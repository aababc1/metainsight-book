{"version":"1","records":[{"hierarchy":{"lvl1":"META-Insight"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"META-Insight"},"content":"Meta-omics Analysis Protocols for Microbiome Research","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"META-Insight","lvl2":"About"},"type":"lvl2","url":"/#about","position":2},{"hierarchy":{"lvl1":"META-Insight","lvl2":"About"},"content":"Metagenomic analysis is an innovative approach to interpreting complex biological information to understand the ecology, function, diversity, and interactions of microbial communities.\n\nOur goal is to introduce state-of-the-art analytical methods that enable accurate meta-omics analysis and provide meta-omics data derived from the accurate gut microbiome of healthy individuals.","type":"content","url":"/#about","position":3},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Key Features"},"type":"lvl2","url":"/#key-features","position":4},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Key Features"},"content":"Metagenome-Assembled Genomes (MAGs): Organizes microbial community information at the genome level\n\nMulti-omics Integration: Combines metagenome, metatranscriptome, and metaproteome data\n\nComprehensive Protocols: Step-by-step analysis pipelines for each omics type","type":"content","url":"/#key-features","position":5},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Protocols"},"type":"lvl2","url":"/#protocols","position":6},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Protocols"},"content":"","type":"content","url":"/#protocols","position":7},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metagenomics","lvl2":"Protocols"},"type":"lvl3","url":"/#metagenomics","position":8},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metagenomics","lvl2":"Protocols"},"content":"De novo genome analysis through shotgun sequencing, supporting both Illumina short reads and PacBio long reads.","type":"content","url":"/#metagenomics","position":9},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metatranscriptomics","lvl2":"Protocols"},"type":"lvl3","url":"/#metatranscriptomics","position":10},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metatranscriptomics","lvl2":"Protocols"},"content":"MAG-based reference-guided and reference-independent analysis for gene expression profiling.","type":"content","url":"/#metatranscriptomics","position":11},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metaproteomics (Ribo-seq)","lvl2":"Protocols"},"type":"lvl3","url":"/#metaproteomics-ribo-seq","position":12},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Metaproteomics (Ribo-seq)","lvl2":"Protocols"},"content":"Alternative method for mass-based analysis using ribosome profiling to quantify protein synthesis.","type":"content","url":"/#metaproteomics-ribo-seq","position":13},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Getting Started"},"type":"lvl2","url":"/#getting-started","position":14},{"hierarchy":{"lvl1":"META-Insight","lvl2":"Getting Started"},"content":"Select a protocol from the sidebar to begin your meta-omics analysis journey.\n\nVersion: 1.0\nContact: \n\nmetainsight@gnu​.ac​.kr","type":"content","url":"/#getting-started","position":15},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Affiliations","lvl2":"Getting Started"},"type":"lvl3","url":"/#affiliations","position":16},{"hierarchy":{"lvl1":"META-Insight","lvl3":"Affiliations","lvl2":"Getting Started"},"content":"Gyeongsang National University\n\nYonsei University\n\nMinistry of Science and ICT","type":"content","url":"/#affiliations","position":17},{"hierarchy":{"lvl1":"Binning"},"type":"lvl1","url":"/binning","position":0},{"hierarchy":{"lvl1":"Binning"},"content":"\n\n\n\nIn metagenome analysis, binning is the process of grouping contigs based on specific criteria, primarily relying on sequence composition and coverage data.\nBy utilizing a binning program to cluster contigs, it becomes possible to reconstruct complete microbial genomes.\nIn addition to \n\nMetaBAT2 we used, other widely used binning programs are \n\nMaxBin 2.0 and \n\nCONCOCT.\n\nTo perform binning using MetaBAT2, a sam file with coverage information is required.\nFor short reads data, this can be obtained by using the BBmap script to map the trimmed sequence to the template of the assembled contigs.\nFor long read data, minimap2 is used instead of bbmap to map reads to contig.# calculate coverage information from short reads assembly\n$ conda activate bbmap\n$ bbmap.sh in=trimmed.reads_1.fastq in2=trimmed.reads_2.fastq covstats=covstats.txt out=MEGAHIT.sam threads=3 ref=/MEGAHIT_result/final.contigs.fa\n$ conda deactivate \n\n# generate bam file from sam file\n$ conda activate samtools\n$ samtools view -bS -o MEGAHIT.bam MEGAHIT.sam -@ 5\n# sort the bam file\n$ samtools sort MEGAHIT.bam –o MEGAHIT.sorted.bam -@ 5\n$ conda deactivate # calculate coverage information  from long reads assembly\n$ conda activate minimap2\n# align host read-filtered read file(N008.aln.unamapped.fq) to assembled contig file(N_008_HiFi.p_ctg.fa)\n$ minimap2 -ax map-hifi N_008_HiFi.p_ctg.fa N008.aln.unmapped.fq > N_008_HiFi.p_ctg_mapped.sam\n$ conda deactivate \n\n# generate bam file from sam file\n$ conda activate samtools\n$ samtools view -bS -o N_008_HiFi.p_ctg_mapped.bam N_008_HiFi.p_ctg_mapped.sam -@ 5\n# sort the bam file\n$ samtools sort N_008_HiFi.p_ctg_mapped.bam -o \n\nCompress and index the formed sam file and convert it to a binary bam file.\n\nWhen the bam file with coverage information is ready, use the jgi_summarize_bam_contig_depth script provided by MetaBAT2 to generate the final depth.txt file and then perform binning with the assembled contigs.$ conda activate MetaBAT2\n# generate depth file from bam file\n$ jgi_summarize_bam_contig_depths --outputDepth jgi.depth.txt MEGAHIT.sorted.bam\n# run MetaBAT2\n$ MetaBAT2 -i final.contigs.fa -a jgi.depth.txt -o bins_dir/bin\n$ conda deactivate \n\nAfter the completion of binning using MetaBAT2, the quality of the bins is assessed using \n\nCheckM.\nCheckM is a program designed to gauge the quality of genomes recovered from isolates, single cells, or metagenomes.\nThe program furnishes information about phylogenetic lineage, genetic characteristics (such as GC contents and coding density), contamination, completeness, and strain heterogeneity.\nIt accomplishes this by analyzing single-copy genes within the genome.$ conda activate CheckM\n# download CheckM database from https://data.ace.uq.edu.au/public/CheckM_databases/\n$ export CHECKM_DATA_PATH=/path/to/my_CheckM_data\n# run CheckM\n$ CheckM lineage_wf –x fa bins_dir bins_CheckM\n\nIt displays the marker lineage and the number of marker genes in the generated bin, along with the completeness, contamination, and strain heterogeneity of the constructed genome in the last three columns.\n\n\n\nExample of CheckM result","type":"content","url":"/binning","position":1},{"hierarchy":{"lvl1":"De novo assembly"},"type":"lvl1","url":"/denovo-assembly","position":0},{"hierarchy":{"lvl1":"De novo assembly"},"content":"\n\n","type":"content","url":"/denovo-assembly","position":1},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Short reads"},"type":"lvl2","url":"/denovo-assembly#short-reads","position":2},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Short reads"},"content":"Read-based profiling offers a rapid overview of the metagenome but is limited by the presence of a significant number of unmapped reads.\nTo overcome this limitation, de novo assembly is employed using assemblers to extend overlapping reads into contigs or scaffolds.\nThis approach enables in-depth profiling of genomic components and the discovery of previously unknown sequences since it is a database-independent process.\n\nCurrently, various assemblers are available. Some assemblers are specifically designed for the efficient assembly of short reads.\nAmong the most widely utilized assemblers, \n\nMEGAHIT and \n\nmetaSPAdes stand out.\nmetaSPAdes is particularly renowned for its performance with high-depth samples. However, it demands a substantial amount of memory, even for small-sized metagenome data.\nMEGAHIT shows competitive assembly quality and efficient memory usage compared to metaSPAdes. \n\n[ref].\n\nMEGAHIT employs k-mers, and the size of these k-mers can be adjusted based on the sample’s complexity using the --k-min and --k-max options.\nWhen dealing with high-depth samples, it is advisable to select a relatively larger k-mer size (typically 25-31) to prevent excessive complexity in the de Bruijn graph.\nConversely, for low-depth samples where the assembly isn’t functioning optimally, you can enhance assembly efficiency by employing the --no-mercy option.\nFor paired-end reads, make sure to specify the forward and reverse read filenames separately using -1 and -2. For single reads, use the -r option.\nThe maximum memory allocated for de Bruijn graph construction can be set using the -m option and the total system memory can be adjusted within the range of 0-1.\nThe default value is typically set to 0.9. The -t option allows you to define the number of CPU threads, with a minimum requirement of 2.\nBy default, the software automatically calculates the available CPU threads and utilizes them collectively.# run MEGAHIT \n$ conda activate MEGAHIT\n$ MEGAHIT -1 kneaddata.trimmed.1.fastq  -2 kneaddata.trimmed.2.fastq  -m 0.5  -t 12 -o MEGAHIT_result\n$ conda deactivate","type":"content","url":"/denovo-assembly#short-reads","position":3},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Long reads assembly"},"type":"lvl2","url":"/denovo-assembly#long-reads-assembly","position":4},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Long reads assembly"},"content":"PacBio HiFi long reads (typically 10–20 kb with >99% accuracy) enable the resolution of repetitive genomic regions and the recovery of near-complete metagenome-assembled genomes that are inaccessible through short-read assembly alone. The assembler \n\nhifiasm-meta is specifically designed for metagenomic HiFi data, producing high-quality primary and alternate contigs by leveraging the length and accuracy of HiFi reads to resolve strain-level haplotypes within complex microbial communities. Unlike short-read assemblers based on de Bruijn graphs, hifiasm-meta uses an overlap-based approach that better preserves long-range genomic structure.# run hifiasm_meta \n$ conda activate hifiam_meta\n$ hifiasm_meta -o N14.asm -t 60 N14.aln.unmapped.fq > N14.log\n$ conda deactivate\n# .gfa 파일을 .fa 파일로 변환\n$ awk '/^S/{print \">\"$2;print $3}' test.p_ctg.gfa > test.p_ctg.fa\n\n“.gfa” stands for graphical fragment assembly, a file format designed to store graph-based assembly information.\nIt contains data about the graph generated during the assembly process.\nThe structure of the graph file is akin to a de Bruijn graph, illustrating the connectivity of nodes and edges.\nThese graphs depict the interactions among overlapping DNA sequences, aiding in the assembly process.\n\nWhen running \n\nHifiasm-meta, the output files are as follows.\n\n1. Raw unitig graph: asm.r_utg*.gfaThis file contains the raw unitig graph generated during the assembly process. The raw unitig graph is the initial graph for assembly, which organizes nodes and edges based on overlapping sequence information.\n2. Cleaned unitig graph: asm.p_utg*.gfaThis file contains preprocessed cleaned unitig graphs. Preprocessing refers to the process of removing errors from the raw unitig graph and improving its accuracy.\n3. Contig graph: asm.p_ctg*.gfa, asm.a_ctg*.gfaThis file contains the contig graph. The file asm.p_ctg*.gfa means primary contig and asm.a_ctg*.gfa means alternate contig.\n\nUnitigA unitig, which stands for unique sequence, is a unit of overlapping DNA sequences that is the result of an intermediate step in assembly. Each unitig consists of one or more DNA sequences and contains overlapping parts. The assembly process generates a raw unitig graph. This raw unitig graph may contain some errors. The subsequent processing removes the errors from the raw unitig graph and generates a cleaned unitig graph.","type":"content","url":"/denovo-assembly#long-reads-assembly","position":5},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Contig check"},"type":"lvl2","url":"/denovo-assembly#contig-check","position":6},{"hierarchy":{"lvl1":"De novo assembly","lvl2":"Contig check"},"content":"Long read assembly results can be visualized using a bandage plot, which is a tool for representing complex assembly results, including De Bruijn graphs or overlap graphs.\nLong read assemblies often yield intricate graphs, and the bandage plot is a good option for visualizing these graphs.\n\nIt provides the following information.\n\nTo generate bandage plots, you can use Bandage, a Bioinformatics Application for Navigating De novo Assembly Graphs Easily. Bandage is available for download at \n\nhttp://​rrwick​.github​.io​/Bandage/.\n\nAfter running the Bandage program, load the *p_ctg.gfa file from File > Load graph at the top. Once the file is loaded, click Draw graph in Graph drawing to display the graph.\n\n\n\n\n\nAfter assembly, check the assembly result and quality using \n\nQUAST(Quality assessment tool) to know the information of the produced contigs.# calculate assembly statistics\n$ conda activate quast\n$ quast.py MEGAHIT_result/final.contigs.fa -o MEGAHIT_quast\n$ conda deactivate\n\n\n\nExample of report.html\n\ncontigs: Number of contigs produced after assembly\n\nLargest contig: The length of the longest contig among the contigs produced after assembly\n\nTotal length: Total number of bases of contigs generated after assembly\n\nN50: Length of the contig with the top 50% length among the contigs generated after assembly\n\nN75: Length of the contig with the top 75% length among the contigs generated after assembly\n\nL50: Number of contigs with the length of N50 among the contigs generated after assembly\n\nL75: Number of contigs with the length of N75 among the contigs generated after assembly\n\nMismatches # N’s: Number of uncalled bases that were not assembled\n\nMismatches # N’s per 100kbp: Number of uncalled bases per 100000 bases\n\nThe left Graph shows cumulative length as the contig index increases and the right graph shows GC contents of contigs\n\n\n\n","type":"content","url":"/denovo-assembly#contig-check","position":7},{"hierarchy":{"lvl1":"Functional annotation of contigs"},"type":"lvl1","url":"/functional","position":0},{"hierarchy":{"lvl1":"Functional annotation of contigs"},"content":"While taxonomic profiling reveals who is present in a microbial community, functional annotation addresses the equally important question of what they can do. Functional annotation assigns biological roles to the predicted genes within assembled contigs or metagenome-assembled genomes (MAGs), linking open reading frames (ORFs) to known metabolic pathways, enzyme functions, and gene ontologies. This step is essential for understanding the metabolic potential of microbial communities and for identifying genes of interest such as antibiotic resistance genes, carbohydrate-active enzymes, or novel biosynthetic gene clusters. In this chapter, we describe gene prediction using Prodigal and functional annotation using eggNOG-mapper against multiple reference databases.\n\n\n\n\n\nAfter completing the taxonomic annotation of contigs, it is necessary to retrieve information about the open reading frame of the contigs to make a functional assignment.\nProdigal can predict protein-coding sequences of prokaryotes and can be used for metagenome analysis in addition to complete or draft genome analysis.# run prodigal\n$ conda activate prodigal\n$ prodigal -i final.contigs.fa -p meta -a final.contigs.prodigal.faa -d final.contigs.prodigal.fna -f gff -o final.contigs.prodigal.gff \n$ conda deactivate\n\nAfter gene prediction is completed, the contig file can be analyzed for functional annotation based on various databases, most commonly \n\nKEGG, \n\nCOG, and \n\nmetaCyc databases, and also specialized databases such as CAZyme [14] and ARDB [15] can be utilized.\nOne of the most widely used functional annotation programs is \n\neggNOG-mapper, which can perform fast functional annotation of novel sequences using the eggNOG database based on orthologs and phylogenies produced by the European Molecular Biology Laboratory (EMBL).\nIn addition to eggNOG-mapper, other tools that can be used are simple BLAST or programs such as \n\nInterProScan.# run eggnog-mapper\n$ conda activate eggnog\n# download eggnog-mapper database\n$ download_eggnog_data.py\n# run eggnog-mapper\n$ emapper.py -m diamond --cpu 5 -i final.contig.prodigal.faa -o eggnog.out\n$ conda deactivate\n\n\n\nExample of report.html\n\nBesides the standalone version, eggNOG-mapper offers a \n\nweb-based analysis service that can accommodate input of up to 100,000 proteins in FASTA format.","type":"content","url":"/functional","position":1},{"hierarchy":{"lvl1":"Metagenomic analysis tools"},"type":"lvl1","url":"/installation","position":0},{"hierarchy":{"lvl1":"Metagenomic analysis tools"},"content":"This chapter provides a comprehensive guide to installing the bioinformatics software required for the metagenomic analysis pipeline described in this protocol. Metagenomic analysis relies on a diverse set of specialized tools spanning quality control, assembly, binning, taxonomic and functional annotation, and phylogenetic reconstruction. Managing these tools and their dependencies can be challenging, particularly when different programs require incompatible software versions. We recommend using Conda, a cross-platform package and environment manager, which allows each tool to be installed in an isolated environment, thereby avoiding version conflicts and ensuring reproducibility across different computing systems.\n\nPreprocessing of the sequencing reads : Kneaddata, minimap2, samtools\n\nRead-based profiling : HUMAnN 3.0, MetaPhlAn\n\nDe novo assembly : MEGAHIT, Quast, hifiasm_meta, Bandage\n\nTaxonomic annotation : Kaiju\n\nFunctional annotation : Prodigal, EggNOG\n\nBinning : MetaBAT2, BBmap, minimap2, samtools, CheckM\n\nPhylogenetic tree construction : GTDB-tk, PhyloPhlAn3\n\n\n\nMetagenomics analysis pipeline","type":"content","url":"/installation","position":1},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl2":"Installation"},"type":"lvl2","url":"/installation#installation","position":2},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl2":"Installation"},"content":"","type":"content","url":"/installation#installation","position":3},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"An introduction to Conda","lvl2":"Installation"},"type":"lvl3","url":"/installation#an-introduction-to-conda","position":4},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"An introduction to Conda","lvl2":"Installation"},"content":"Metagenomic analysis necessitates the installation of various analysis programs, a process that can sometimes result in conflicts or version dependencies between these programs.\nFor instance, when program A relies on a specific version of program B, and program C depends on a different version of program B, it can be challenging and time-consuming for beginners to set up program C.\nIn such scenarios, conda, a Python package and environment management tool, offers an effective solution for resolving these version conflicts.\n\nFor this Standard Operating Procedure (SOP), we recommend installing the analysis tools using conda.\nYou can find the official documentation for conda at the following \n\nwebsite.\nThis approach ensures a smoother and more efficient installation process, making metagenomic analysis more accessible and less prone to compatibility issues.","type":"content","url":"/installation#an-introduction-to-conda","position":5},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"Making a new environment","lvl2":"Installation"},"type":"lvl3","url":"/installation#making-a-new-environment","position":6},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"Making a new environment","lvl2":"Installation"},"content":"It is highly recommended to create a new conda environment every time you install a program. Doing so helps to avoid conflicts between programs and ensures a clean, isolated environment for each analysis tool.\nAn example of how to create a new conda environment is provided below.# Create a new conda environment\n$ conda create -n new-env \n\nUse the conda create command with the -n flag to designate and save the name of your new environment.","type":"content","url":"/installation#making-a-new-environment","position":7},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"Entering & exiting an environment","lvl2":"Installation"},"type":"lvl3","url":"/installation#entering-exiting-an-environment","position":8},{"hierarchy":{"lvl1":"Metagenomic analysis tools","lvl3":"Entering & exiting an environment","lvl2":"Installation"},"content":"# Enter that environment\n$ conda activate new-env\n# Exit whatever conda environment we are running\n$ conda deactivate\n\nThe table below provides example installation codes and Anaconda addresses for the programs used in this SOP.\n\nProgram\n\nInstallation code\n\nANACONDA addresses\n\nKNEDDATA\n\nconda create -n kneaddata -c bioconda kneaddata\n\nhttps://​anaconda​.org​/bioconda​/kneaddata\n\nHUMANN3.0\n\nconda create -n humann -c biobakery humann\n\nhttps://​anaconda​.org​/biobakery​/humann\n\nMETAPHLAN3.0\n\nconda create –n metaphlan -c bioconda metaphlan\n\nhttps://​anaconda​.org​/bioconda​/metaphlan\n\nMEGAHIT\n\nconda create –n MEGAHIT -c bioconda MEGAHIT\n\nhttps://​anaconda​.org​/bioconda​/MEGAHIT\n\nQUAST\n\nconda create –n quast -c bioconda quast\n\nhttps://​anaconda​.org​/bioconda​/quast\n\nKAIJU\n\nconda create –n kaiju -c bioconda kaiju\n\nhttps://​anaconda​.org​/bioconda​/kaiju\n\nMINIMAP2\n\nconda create –n minimap2 -c bioconda minimap2\n\nhttps://​anaconda​.org​/bioconda​/minimap2\n\nHIFIASM_META\n\nconda create –n hifiasm_meta -c bioconda hifiasm_meta\n\nhttps://​anaconda​.org​/bioconda​/hifiasm​_meta\n\nKRONA\n\nconda create –n krona -c bioconda krona\n\nhttps://​anaconda​.org​/bioconda​/krona\n\nPRODIGAL\n\nconda create –n prodigal -c bioconda prodigal\n\nhttps://​anaconda​.org​/bioconda​/prodigal\n\nEGGNOG\n\nconda create –n eggnog -c bioconda eggnog-mapper\n\nhttps://​anaconda​.org​/bioconda​/eggnog​-mapper\n\nMETABAT2\n\nconda create –n MetaBAT2 -c bioconda MetaBAT2\n\nhttps://​anaconda​.org​/bioconda​/MetaBAT2\n\nBBMAP\n\nconda create –n bbmap -c bioconda bbmap\n\nhttps://​anaconda​.org​/bioconda​/bbmap\n\nSAMTOOLS\n\nconda create –n samtools -c bioconda samtools\n\nhttps://​anaconda​.org​/bioconda​/samtools\n\nCHECKM\n\nconda create -n CheckM python=3.9  conda activate CheckM conda install -c bioconda numpy matplotlib pysamconda install -c bioconda hmmer prodigal pplacerpip3 install CheckM-genome\n\nhttps://​anaconda​.org​/bioconda​/CheckM​-genome\n\nGTDB-TK\n\nconda create -n gtdbtk-2.1.1 -c conda-forge -c bioconda gtdbtk=2.1.1\n\nhttps://​anaconda​.org​/bioconda​/gtdbtk\n\nPHYLOPHLAN3\n\nconda create –n phylophlan -c bioconda phylophlan\n\nhttps://​anaconda​.org​/bioconda​/phylophlan","type":"content","url":"/installation#entering-exiting-an-environment","position":9},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis"},"type":"lvl1","url":"/introduction","position":0},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis"},"content":"","type":"content","url":"/introduction","position":1},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl2":"Introduction to metagenome"},"type":"lvl2","url":"/introduction#introduction-to-metagenome","position":2},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl2":"Introduction to metagenome"},"content":"\n\nMetagenomics overview\n\nA metagenome is the pool of genetic material present in various environmental samples (animal, plant, marine, etc.).\nMetagenomic analysis extracts and analyzes the genetic information of all organisms present in a given environmental ecosystem.\nBefore the rise of metagenomics, microbial genomes could only be analyzed from culturable microorganisms. However, since only a small fraction of the microbes in a given environment are culturable, this approach results in biased information centered on culturable microbes.\nMetagenomic analyses, on the other hand, analyze the entire genome of an environment, providing a more accurate picture of a given ecosystem.\n\nAdvancements in sequencing technology have made it easier for researchers to access whole metagenome shotgun sequencing, which sequences billions of nucleic acid fragments at once, beyond amplicon sequencing, which involves targeted amplification and sequencing of specific parts of the genome such as 16S ribosomal DNA, and the demand for research has increased.\nFor amplicon sequencing data, there are standard analysis protocols and platforms such as QIIME2, but for WMS analysis, there is no standard gold-standard analysis SOP.\nIn this SOP, we will describe the methods and flow for analyzing whole genome sequencing (WGS) data, focusing on the most commonly used tools among various analysis programs.\n\n","type":"content","url":"/introduction#introduction-to-metagenome","position":3},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl2":"Sequencing Technology Selection"},"type":"lvl2","url":"/introduction#sequencing-technology-selection","position":4},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl2":"Sequencing Technology Selection"},"content":"Choosing the appropriate sequencing platform is one of the most critical decisions in metagenomic study design, as it directly determines the achievable resolution of taxonomic classification, assembly completeness, and overall analytical scope. Currently, three major platforms dominate the field: Illumina (short-read), Pacific Biosciences (PacBio, long-read), and Oxford Nanopore Technologies (ONT, long-read). Each platform has distinct strengths and trade-offs that must be carefully considered based on the research objectives, available budget, and sample characteristics.","type":"content","url":"/introduction#sequencing-technology-selection","position":5},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Platform Comparison","lvl2":"Sequencing Technology Selection"},"type":"lvl3","url":"/introduction#platform-comparison","position":6},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Platform Comparison","lvl2":"Sequencing Technology Selection"},"content":"Feature\n\nIllumina NovaSeq 6000\n\nPacBio Revio (HiFi)\n\nONT PromethION\n\nRead length\n\nUp to 2 × 250 bp\n\n15–18 kb\n\nup to 4 Mb (avg ~20 kb)\n\nRead accuracy\n\n~99.75% (Q30+)\n\n>99.5% (Q30+)\n\n97–99% (Q20+)\n\nYield per run\n\n~350 Gb\n\n~90 Gb per SMRT Cell (×4)\n\n~120 Gb\n\nCost per Gb\n\n~US$4\n\n~US$8–11\n\n~US$6–12\n\nDNA input\n\n1–500 ng\n\n150 ng – 1 µg\n\n150 ng – 1 µg\n\nRuntime\n\n13–44 h\n\n~24 h\n\n~72 h\n\nDirect RNA-seq\n\nNo\n\nNo\n\nYes\n\nPortability\n\nLow\n\nLow\n\nHigh (MinION)\n\nNote: Sequencing costs are estimates and subject to rapid changes\n\n.","type":"content","url":"/introduction#platform-comparison","position":7},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"When to Choose Short Reads (Illumina)","lvl2":"Sequencing Technology Selection"},"type":"lvl3","url":"/introduction#when-to-choose-short-reads-illumina","position":8},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"When to Choose Short Reads (Illumina)","lvl2":"Sequencing Technology Selection"},"content":"Short-read sequencing remains the most widely adopted approach in metagenomics due to its low cost per gigabase, high base-level accuracy, and lower DNA input requirements. It is particularly well-suited for:\n\nCommunity profiling and abundance estimation — when the primary goal is to determine which organisms are present and at what relative abundance, short reads provide cost-effective, high-throughput results.\n\nFunctional gene catalog construction — read-based profiling tools such as HUMAnN and MetaPhlAn are optimized for short-read data.\n\nDifferential abundance studies — when comparing microbial communities across many samples (e.g., case-control studies), the lower per-sample cost of short reads enables larger sample sizes.\n\nLow-biomass samples — Illumina library preparation with PCR amplification can work with as little as 1 ng of input DNA, an important advantage when sample material is limited.\n\nHowever, short reads have well-documented limitations. Repetitive genomic regions longer than the read length (~250 bp) cannot be resolved, resulting in fragmented assemblies. This makes it difficult to recover complete genomes (MAGs), characterize mobile genetic elements (plasmids, transposons), and distinguish closely related strains that differ in only a few genomic loci.","type":"content","url":"/introduction#when-to-choose-short-reads-illumina","position":9},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"When to Choose Long Reads (PacBio HiFi or ONT)","lvl2":"Sequencing Technology Selection"},"type":"lvl3","url":"/introduction#when-to-choose-long-reads-pacbio-hifi-or-ont","position":10},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"When to Choose Long Reads (PacBio HiFi or ONT)","lvl2":"Sequencing Technology Selection"},"content":"Long-read sequencing has matured considerably in recent years, with significant improvements in accuracy, throughput, and cost. Long reads are recommended when the study requires:\n\nComplete or near-complete MAGs — long reads can span repetitive regions and resolve strain-level haplotypes, enabling the assembly of circularized genomes directly from metagenomic samples. For example, PacBio HiFi reads with hifiasm-meta have been shown to circularize 56 genomes from human gut microbiome samples.\n\nStrain-level resolution — intergenomic repeats (sequences shared between related organisms) are difficult to resolve with short reads alone. Long reads increase the likelihood that a read includes an organism-specific region, improving taxonomic classification at species and sub-species levels.\n\nStructural variant detection — insertions, deletions, inversions, and other large-scale genomic rearrangements (>50 bp) are far more reliably detected with long reads.\n\nMethylation analysis — both PacBio and ONT can detect DNA methylation patterns (5mC, 6mA, 4mC) directly during sequencing without bisulfite conversion, enabling epigenomic characterization of microbial communities.\n\nPlasmid and mobile element recovery — short-read assemblies disproportionately fail for multi-copy DNA elements such as 16S genes, transposons, and plasmids. Long reads overcome this by spanning entire elements in single reads.","type":"content","url":"/introduction#when-to-choose-long-reads-pacbio-hifi-or-ont","position":11},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl4":"PacBio HiFi vs. ONT","lvl3":"When to Choose Long Reads (PacBio HiFi or ONT)","lvl2":"Sequencing Technology Selection"},"type":"lvl4","url":"/introduction#pacbio-hifi-vs-ont","position":12},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl4":"PacBio HiFi vs. ONT","lvl3":"When to Choose Long Reads (PacBio HiFi or ONT)","lvl2":"Sequencing Technology Selection"},"content":"Consideration\n\nPacBio HiFi\n\nONT\n\nBest for\n\nHigh-accuracy MAG assembly, variant calling\n\nRapid/field sequencing, ultra-long reads, direct RNA-seq\n\nAccuracy\n\n>99.5% (comparable to Illumina)\n\n97–99% (improving with R10 chemistry)\n\nRead length\n\n15–18 kb (consistent)\n\nUp to 4 Mb (variable, avg ~20 kb)\n\nMethylation\n\n5mC, 6mA\n\n5mC, 6mA, 4mC + RNA modifications\n\nPortability\n\nLab-based only\n\nMinION/Flongle can be used in field settings\n\nError correction needed\n\nRarely (HiFi reads are self-corrected)\n\nOften recommended before assembly","type":"content","url":"/introduction#pacbio-hifi-vs-ont","position":13},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Hybrid Approach (Short + Long Reads)","lvl2":"Sequencing Technology Selection"},"type":"lvl3","url":"/introduction#hybrid-approach-short-long-reads","position":14},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Hybrid Approach (Short + Long Reads)","lvl2":"Sequencing Technology Selection"},"content":"A hybrid sequencing strategy combines the strengths of both technologies: the high base-level accuracy of short reads with the long-range contiguity information from long reads. Hybrid assembly tools such as OPERA-MS, Unicycler, and DBG2OLC can leverage both data types to produce assemblies with improved contiguity, gene completeness, and binning accuracy compared to short-read-only approaches.\n\nHowever, hybrid approaches involve higher costs (two library preparations and sequencing runs) and can introduce biases from combining different library preparation chemistries. With the increasing accuracy of PacBio HiFi reads (>Q30), long-read-only assemblies are now achieving comparable or superior quality to hybrid assemblies for many applications, making the hybrid approach less necessary than in previous years.","type":"content","url":"/introduction#hybrid-approach-short-long-reads","position":15},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Decision Framework","lvl2":"Sequencing Technology Selection"},"type":"lvl3","url":"/introduction#decision-framework","position":16},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metagenome Analysis","lvl3":"Decision Framework","lvl2":"Sequencing Technology Selection"},"content":"The choice of sequencing strategy depends on the study’s objectives:\n\nResearch Goal\n\nRecommended Strategy\n\nLarge-scale community profiling (many samples)\n\nIllumina short reads\n\nComplete genome recovery (MAGs)\n\nPacBio HiFi or ONT + polishing\n\nStrain-level resolution\n\nLong reads (PacBio or ONT)\n\nPlasmid / mobile element tracking\n\nLong reads\n\nAntibiotic resistance gene surveillance\n\nONT (rapid, portable)\n\nLow-biomass / clinical samples\n\nIllumina (low DNA input)\n\nMulti-omics integration (DNA + RNA)\n\nONT (direct RNA-seq capability)\n\nBudget-constrained study\n\nIllumina (lowest cost/Gb)\n\nIn this SOP, we provide analysis pipelines for both Illumina short-read and PacBio HiFi long-read metagenomics, covering sample preparation through computational analysis for each approach.","type":"content","url":"/introduction#decision-framework","position":17},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"type":"lvl1","url":"/preprocessing","position":0},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"content":"Raw sequencing data inevitably contains artifacts that must be removed before downstream analysis. These artifacts include low-quality bases introduced during the sequencing process, adapter sequences ligated during library preparation, and reads originating from the host genome rather than the microbial community of interest. Preprocessing—also referred to as quality control (QC) and read filtering—is a critical first step that directly affects the accuracy of assembly, taxonomic profiling, and functional annotation. In this chapter, we describe preprocessing workflows for both short-read (Illumina) and long-read (PacBio HiFi) metagenomic data, using KneadData and minimap2, respectively.\n\n\n\n","type":"content","url":"/preprocessing","position":1},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Short reads"},"type":"lvl2","url":"/preprocessing#short-reads","position":2},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Short reads"},"content":"For quality control of raw sequence data, two crucial steps are (1) removing low-quality bases and (2) eliminating artifacts such as barcodes, adaptors, and chimeras.\n\n\nKneadData employs \n\nTrimmomatic for quality filtering and trimming and Tandem Repeat Finder (TRF) for read preprocessing.\nAdditionally, it utilizes \n\nBowtie2 for FastQC analysis and read alignment.\nWhen using Trimmomatic, you can specify the minimum length of the sequence as a percentage of the input read with the --trimmomatic-options='MINLEN:' parameter.# Downlodad host genome (ex.Human)\n$ conda activate kneaddata\n$ mkdir hostgenome\n$ kneaddata_database --download human_genome bowtie2 hostgenome/\n$ kneaddata --input1 input/seq1.fastq --input2 input/seq2.fastq --reference-db hostgenome/ --output kneaddataOutputPairedEnd --trimmomatic-options=\"MINLEN:90\"  \n$ conda deactivate\n\n▶Example of KneadData output\n\n\n\n\n\n▶Example of Output files\n\nseq.kneaddata_human_genome_bowtie2_contam.fastq\n: Contaminant reads aligned to the human genome\n\nseq.kneaddata.fastq\n: Reads not aligned to the human genome\n\nseq.kneaddata.trimmed.fastq\n: trimmed reads\n\nseq.kneaddata.log\n: log file","type":"content","url":"/preprocessing#short-reads","position":3},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Long reads"},"type":"lvl2","url":"/preprocessing#long-reads","position":4},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Long reads"},"content":"The mapping methods typically employed for short reads are not well-suited for long reads.\nShort reads are commonly mapped using the seed-and-extend method, which extends based on single base matches.\nHowever, long reads require multiple consistent matches across the read for accurate alignment.\nWhen seed-and-extend methods are applied to long reads, issues with extension and alignment accuracy can arise.\nTo address these challenges, alternative methods like seed-and-chain have been developed.\n\nminimap2 is a versatile sequence mapping program that is effective for aligning and analyzing long reads such as PacBio and Oxford Nanopore technologies.\nIn this pipeline, we will use minimap2 for long read mapping.$ conda install -c bioconda minimap2\n$ conda activate minimap2\n# General usage of minimap2\n# minimap2 –ax map-hifi ref.fa query.fq > alignment.sam\n$ minimap2 -ax map-hifi GCF_000001405.40_GRCh38.p14_genomic.fna N_008_HiFi.fastq.gz > N008.aln.sam\n# Convert sam files to bam files\n$ samtools view -Sb N008.aln.sam > N008.aln.bam \n# remove host genome aligned read\n$ samtools view -bf 0x04 N008.aln.bam > N008.aln.unmapped.bam\n# convert bam files to fastq\n$ samtools bam2fq N008.aln.unmapped.bam > N008.aln.unmapped.fq","type":"content","url":"/preprocessing#long-reads","position":5},{"hierarchy":{"lvl1":"Read-based profiling"},"type":"lvl1","url":"/read-based","position":0},{"hierarchy":{"lvl1":"Read-based profiling"},"content":"The methods for analyzing preprocessed reads can be categorized into two main approaches: read-based profiling and assembly-based profiling.\nRead-based profiling involves taxonomic and functional profiling without the need for assembly, primarily relying on k-mer matching.\nThis approach is particularly useful for analyzing low-depth samples that are challenging to assemble. It offers the advantage of faster analysis completion.\n\nHUMAnN 3.0, for instance, utilizes the MetaPhlAn program for pre-taxonomic profiling.\nIt then employs a translated search to examine unmapped reads, facilitating further analysis and quantification of gene families and pathways across the entire pangenomes.# download database\n$ conda activate humann\n$ humann_databases --download chocophlan full /database/humann\n$ humann_databases --download uniref uniref90_diamond /database/humann\n# concatenate all reads into a single FASTAQ file\n$ cat kneaddata.trimmed.1.fastq kneaddata.trimmed.2.fastq > kneaddata.trimmed.fastq\n# run human 3.0\n$ humann3 --input kneaddata.trimmed.fastq --output humann3_out/ --nucleotide-database /database/humann/chocophlan/ --protein-database /database/humann/uniref/\n\n▶Example of output files\n\nHUMAnN 3.0_genefamilies.tsv: Gene family abundance, calculated as reads per kilobase (RPK) value. If the taxonomy assignment is successful, the contribution value is assigned to each microorganism and divided. Gene families are presented in the first column with the UniRef90 identifier, separated by ‘|’ or labeled as ‘UniRef90_unknown’ if no identifier is available.\n\n\n\n\n\nHUMAnN 3.0_pathabundance.tsv: Represents the pathway abundance of each sample and is calculated as an RPK value, the same as the gene family result. It is divided according to the contribution of each microorganism.\n\n\n\n\n\nTo compare gene families across samples with different sequencing depths, normalization can be performed by obtaining relative abundance numbers (relab) or counts per million (CPM), which is the copy number of a gene divided by one million reads.\nThis can be done by specifying cpm or relab in the --units option of the Human_renorm_table command.# Normalization \n$ humann_renorm_table --input Trimmed_paired_merged_genefamilies.tsv --output Trimmed_paired_merged_genefamilies_relab.tsv --units cpm\n\n\n\n\n\nAfter normalization, UniRef gene families can be grouped into reaction units in the default database, MetaCyc, and abundances can be reconstructed.# Generate barplot for specific pathway\n$ humann_barplot --input Trimmed_paired_merged_genefamilies_relab.tsv --output plot1.png --focal-feature 2-ISOPROPYLMALATESYN-RXN\n# Generate sorted barplot by total sum of abundances\n$ humann_barplot --input Trimmed_paired_merged_genefamilies_relab.tsv --output plot2_sorted.png --focal-feature 2-ISOPROPYLMALATESYN-RXN -–sort sum \n# Generate sorted barplot by bray-curtis distance and facetted by genera\n$ humann_barplot --input Trimmed_paired_merged_genefamilies_relab.tsv --output plot3_sorted_facetted.png --focal-feature COA-PWY -–sort braycurtis –-as-genera –-remove-zeros\n\nAfter grouping by reaction, you can plot specific reactions, sort bar graphs based on the sum of their total abundance, sort bar graphs based on their Bayesian distance, or facet by genera.\n\n\n\nBar plot for METSYN_PWY (plot1.png)\n\n\n\nSorted bar plot for METSYN_PWY (plot1_sorted.png)\n\n\n\nSorted and facetted bar plot for COA-PWY","type":"content","url":"/read-based","position":1},{"hierarchy":{"lvl1":"Preparation for sequencing"},"type":"lvl1","url":"/sequencing","position":0},{"hierarchy":{"lvl1":"Preparation for sequencing"},"content":"The quality of metagenomic analysis is fundamentally determined by the quality of the input DNA. This chapter describes the sample collection, storage, and DNA extraction protocols optimized for both Illumina short-read and PacBio long-read whole metagenome shotgun (WMS) sequencing. Proper sample handling and DNA preparation are essential to ensure high sequencing yield, minimize host contamination, and preserve the microbial community composition representative of the original environment. Short-read sequencing requires high-purity DNA with minimal fragmentation, while long-read sequencing demands high-molecular-weight DNA with minimal shearing, necessitating different extraction approaches.","type":"content","url":"/sequencing","position":1},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"Biological samples"},"type":"lvl2","url":"/sequencing#biological-samples","position":2},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"Biological samples"},"content":"Consistent and standardized sample collection is the foundation of reproducible metagenomic studies. The method of collection, preservation, and storage directly influences the DNA yield, microbial community composition, and downstream sequencing quality. Immediate freezing at -80°C minimizes shifts in community structure caused by continued microbial growth or cell lysis at ambient temperatures.\n\nCollect the fecal sample using the sampling spoon and spatula of the fecal collection kit (NBG-4, Noble Biosciences), shake well to homogenize the sample, and store at -80℃.","type":"content","url":"/sequencing#biological-samples","position":3},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"DNA preparation for short reads sequencing"},"type":"lvl2","url":"/sequencing#dna-preparation-for-short-reads-sequencing","position":4},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"DNA preparation for short reads sequencing"},"content":"Illumina short-read sequencing requires high-purity, double-stranded DNA free of PCR inhibitors. Bead-beating-based mechanical lysis (FastDNA SPIN Kit) is recommended for fecal samples because it efficiently disrupts both Gram-positive and Gram-negative bacterial cell walls, providing a more complete representation of the microbial community compared to chemical lysis alone. The protocol below typically yields 1–10 µg of DNA suitable for standard shotgun library preparation.","type":"content","url":"/sequencing#dna-preparation-for-short-reads-sequencing","position":5},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"Reagents","lvl2":"DNA preparation for short reads sequencing"},"type":"lvl3","url":"/sequencing#reagents","position":6},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"Reagents","lvl2":"DNA preparation for short reads sequencing"},"content":"FastDNA SPIN Kit for Feces (MP Biomedicals)\n\nSodium Phosphate Buffer (MP Biomedicals), MT Buffer (MP Biomedicals), PLS Solution (MP Biomedicals), PPS Solution (MP Biomedicals), Wash Buffer #1(MP Biomedicals), Wash Buffer #2 (MP Biomedicals), TES (MP Biomedicals), 100% ethanol","type":"content","url":"/sequencing#reagents","position":7},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"DNA extraction","lvl2":"DNA preparation for short reads sequencing"},"type":"lvl3","url":"/sequencing#dna-extraction","position":8},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"DNA extraction","lvl2":"DNA preparation for short reads sequencing"},"content":"Transfer 500 mg of the fecal sample onto ice into a lysing matrix E tube using a sterilized spatula in a fume hood.\n\nAdd 825 μl of sodium phosphate buffer and 825 μl of PLS solution. Close the lid, and vortex for 10-15 seconds to loosen the sample in the tube.\n\nCentrifuge the sample at 14,000×g for 5 minutes and discard the supernatant.\n\nAdd 978 μl of sodium phosphate buffer and 122 μl of MT buffer. Vortex again until the sample is resuspended.\n\nHomogenize the sample by vortexing at 6.0 m/s for 40 seconds using a beadbeater, such as the FastPrep 24 instrument. If it appears that there was insufficient homogenization due to large debris, perform additional homogenization under the same conditions for all samples, but with careful intervals and attention to the heat generated by the vibration.\n\nCentrifuge the sample at 14,000×g for 5 minutes and transfer the supernatant to a 2 ml tube.\n\nAdd 250 μl of PPS solution. Invert slowly (do not vortex) and keep at 4°C for 10 minutes, then centrifuge at 14,000×g for 2 minutes.\n\nTransfer 1 ml of the binding matrix solution to a 15 ml conical tube during centrifugation.\n\nTransfer the supernatant from the centrifuged sample to the 15 ml tube containing the binding matrix solution. Invert.\n\nPlace the tube in the shaking incubator at an angle that allows the sample to mix well and let it sit for 3-5 minutes.\n\nCentrifuge at 14,000×g for 2 minutes and discard the supernatant.\n\nAdd 1 ml of wash buffer #1 and gently resuspend the pellet.\n\nTransfer 600 μl of the binding matrix and wash buffer #1 mixture to a SPIN filter tube. Centrifuge at 14,000×g for 1 minute, empty the catch tube, transfer the remaining solution, and centrifuge again. Empty the catch tube once more.\n\nAdd 500 μl of wash buffer #2 (ethanol added) to the SPIN filter tube and gently pipette to resuspend (do not vortex).\n\nCentrifuge at 14,000×g for 2 minutes and empty the catch tube.\n\nCentrifuge again at 14,000×g for 2 minutes to remove any remaining wash buffer and dry the pellet.\n\nTransfer the SPIN filter bucket to a new 1.9 ml catch tube and add 60-100 μl of TES solution. Gently tap the tube using your fingertips to mix the pellet with the solution. (Do not vortex)\n\nCentrifuge at 14,000×g for 2 minutes to elute the DNA from the pellet.\n\nQuantify using a NanoDrop and store the eluted DNA frozen at -20°C.","type":"content","url":"/sequencing#dna-extraction","position":9},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"DNA preparation for long reads seqencing"},"type":"lvl2","url":"/sequencing#dna-preparation-for-long-reads-seqencing","position":10},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl2":"DNA preparation for long reads seqencing"},"content":"","type":"content","url":"/sequencing#dna-preparation-for-long-reads-seqencing","position":11},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"Reagents","lvl2":"DNA preparation for long reads seqencing"},"type":"lvl3","url":"/sequencing#reagents-1","position":12},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"Reagents","lvl2":"DNA preparation for long reads seqencing"},"content":"QIAamp PowerFecal DNA kit (Qiagen)We employed the QIAamp PowerFecal DNA kit (Qiagen), as recommended by PacBio. This choice was made because long-read sequencing demands a substantial amount of DNA, and it is crucial to minimize DNA fragmentation.","type":"content","url":"/sequencing#reagents-1","position":13},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"DNA extraction","lvl2":"DNA preparation for long reads seqencing"},"type":"lvl3","url":"/sequencing#dna-extraction-1","position":14},{"hierarchy":{"lvl1":"Preparation for sequencing","lvl3":"DNA extraction","lvl2":"DNA preparation for long reads seqencing"},"content":"DNA extraction from feces was performed following the protocol of the kit manufacturer.","type":"content","url":"/sequencing#dna-extraction-1","position":15},{"hierarchy":{"lvl1":"Taxonomic annotation of contigs"},"type":"lvl1","url":"/taxonomic","position":0},{"hierarchy":{"lvl1":"Taxonomic annotation of contigs"},"content":"\n\n\n\nTaxonomic profiling of metagenome datasets can be categorized into three main methods. (1) DNA-to-DNA, (2) DNA-to-protein, and (3) DNA-to-marker genes.\nThe commonly used method (1) is similar to BLASTn and uses a genomic database, while (2) is similar to BLASTx and requires a protein database.\n\n\n\n>Comparison of the taxonomic classification tools ; \n\n[ref]\n\nEach program has its advantages and disadvantages. DNA-to-DNA methods are known for their speed and low memory consumption, but they are generally less sensitive than DNA-to-protein methods.\nConversely, DNA-to-protein methods tend to be slower and more resource-intensive in terms of memory and CPU usage.\nHowever, their advantage lies in their sensitivity and accuracy since they are based on amino acid sequences.\nThe choice of the best program depends on the nature of the data you are analyzing and your database.\nKaiju is one of the representative DNA-to-protein programs, utilizing the NCBI taxonomy and protein reference database for the classification of microorganisms and viruses.\n\nTo run the \n\nKaiju program, you need to download databases, and the duration of this process may vary based on your computer’s performance.\nThe table below lists the available databases.\n\n\n\n# creating the reference database and index from NCBI nr database\n$ conda activate kaiju\n$ kaiju-makedb -s nr\n\nFiles generated after the Makedb command : Kaiju_db_nr.fmi, nodes.dmp, names.dmp$ kaiju -t nodes.dmp -f nr/kaiju_db_nr.fmi -i MEGAHIT_result/final.contigs.fa -o kaiju.out -z 15\n$ kaiju2krona -t nodes.dmp -n names.dmp -i kaiju.out -o kaiju.out.krona\n$ conda deactivate\n$ conda activate krona\n$ ktImportText -o kaiju.out.html kaiju.out.krona\n$ conda deactivate\n$ conda activate kaiju\n$ kaiju2table -t nodes.dmp -n names.dmp -r genus -o kaiju_summary.tsv kaiju.out -l superkingdom,phylum,class,order,family,genus,species\n$ kaiju-addTaxonNames -t nodes.dmp -n names.dmp -i kaiju.out -o kaiju.names.out\n$ conda deactivate\n\nThree options (-t, -f, and -i) are required to run the kaiju program.\nThe -t option requires nodes.dmp, the -f option requires kaiju_db_nr.fmi, and the -i option requires assembled contig file(final.contigs.fa).\nThe -o option sets the name of kaiju’s output file, and the -z option allows you to adjust the number of CPU threads.\nTo visualize the results of kaiju’s analysis, convert the kaiju.out file into an input file for the Krona program with the kaiju2krona command.\nAfter that, you can activate the Krona program and get the visualization result file in html format through the ktImportText command.\nThe results of Kaiju’s analysis can also be downloaded as a tsv file using the kaiju2table command, with the option -i to specify the rank of the taxon.\n\n\n\n","type":"content","url":"/taxonomic","position":1},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/phylogenetic","position":0},{"hierarchy":{"lvl1":""},"content":"# Phylogenomic tree construction of the MAG\n\n\n\n\n\nThere are various methods for performing taxonomic assignment after recovering multiple genomes from a metagenome.\nAmong these methods, the \n\nGTDB database and \n\nGTDB-tk, which facilitates classification, are among the most commonly used.\nGTDB is a database that compiles information about metagenome-assembled genomes (MAGs) recovered from diverse environmental samples based on data from RefSeq and GenBank.\n\nGTDB-tk consists of multiple steps, including an identification step that utilizes Prodigal and HMMER, an alignment step for concatenating marker genes, and a classification step that involves comparison with the GTDB reference tree using the pplacer program and the maximum-likelihood placement technique.\nAdditionally, a single command, classify_wf, is available to combine these three steps into one streamlined process.$ conda activate gtdbtk\n# Download GTDB-Tk reference data & set the database PATH\n$ wget https://data.gtdb.ecogenomic.org/releases/latest/auxillary_files/gtdbtk_v2_data.tar.gz\n$ tar xvzf gtdbtk_v2_data.tar.gz\n$ export GTDBTK_DATA_PATH=/path/to/unarchived/gtdbtk/release000\n# run GTDB-tk (gene calling)\n$ gtdbtk identify --genome_dir bins_dir/bin --out_dir /gtdbtk/identify --extension fa --cpus 2\n# run GTDB-tk (align)\n$ gtdbtk align --identify_dir /gtdbtk/identify --out_dir /gtdbtk/align --cpus 2\n# run GTDB-tk (classify)\n$ gtdbtk classify --genome_dir /gtdbtk/genomes --align_dir /gtdbtk/align --out_dir /gtdbtk/classify -x fa --cpus 2\n$ conda deactivate\n\n\n\n\n\nBesides \n\nGTDB-tk, another widely used program is \n\nPhyloPhlAn. This program is known for its accuracy and speed.\nIt enables the characterization and construction of phylogenetic trees for microbial genomes and offers simple visualization options.$ conda activate phylophlan3\n$ phylophlan_metagenomic -i bins_dir -o output_metagenomic --nproc 4 -n 1 -d SGB.Jan19 --verbose 2>&1\n$ phylophlan_draw_metagenomic -i output_metagenomic.tsv -o output_heatmap --map bin2meta.tsv --top 20 --verbose 2>&1\n$ conda deactivate\n\nThe phylophlan_metagenomic command in PhyloPhlAn 3.0 allows you to assign the closest species-level genome bins (SGBs) for each bin obtained from metagenome assembly analysis.\nWhen using this command, you can adjust the number of CPU threads via the -nproc option.\nAdditionally, you can determine the number of SGBs to report for each input bin using the -n option, with a default value of 10.\n\nThis command generates three output files that list SGBs based on the average mash distance of the bins.\nTo visualize the output as a heatmap, you can utilize the phylophlan_draw_metagenomic command.\nIn this process, a mapping file for the bins entered in the --map option should be in .tsv file format.\n\n\n\n","type":"content","url":"/phylogenetic","position":1},{"hierarchy":{"lvl1":"Reads alignment"},"type":"lvl1","url":"/alignment-1","position":0},{"hierarchy":{"lvl1":"Reads alignment"},"content":"\n\n\n\nIn this approach, after pre-processing, where fastq files are processed to enhance sequence quality, alignment is performed by mapping the reads to the reference sequences*. The STAR program is utilized to create the reference file and perform the mapping of reads to the generated reference sequences.\n\nTypes of Reference Sequences\n1.Final.contig.fa obtained from metagenome de novo assembly pipeline analysis.\n\nMAG.fa obtained from metagenome MAG binning results.#building STAR index\n$ STAR --runMode genomeGenerate --genomeSAindexNbases 10 --runThreadN 8 --genomeDir ./index/sample --genomeFastaFiles sample_MAG.fa \n#mapping\n$ STAR --genomeDir ./index/sample --runThreadN 8 --readFilesIn ./1.Trim/sample_kneaddata_paired_1.fastq ./1.Trim/sample_kneaddata_paired_2.fastq --outFileNamePrefix ./2.Align/sample_\n\nBy utilizing the STAR runMode command, index files for STAR running are generated from the MAG.fa file of the metagenome. These created index files serve as a basis for mapping reads to reference sequences, resulting in a .sam file where information about gene counts is assigned to each gene.\nThe STAR alignment results are not output separately but are stored in the final.out file. The results of read alignment can be verified using the Log.final.out file, which provides information about the total unique reads, multi-mapping reads, and unmapped reads. Due to the large size of the STAR-generated .sam files, they are converted into smaller-sized binary format .bam files.To align the mapping information after read mapping, the samtools’ view and sort functions are utilized to transform the .sam files into .bam files.#install samtools\n$ tar -xvf samtools.zip\n$ cd samtools\n$ ./configure -prefix==/where/to/install\n$ make\n$ make install\n#sam file sorting and indexing\n$ samtools view -b -F 4 sample_Aligned.out.sam | samtools sort - > sample.bam\n$ samtools index sample.bam\n\nOnce these .bam files are generated, you can visualize the alignment results using the IGV program. To examine the alignment results with the IGV program, you will need the MAG.fa obtained from metagenome de novo assembly or MAG results. If you wish to display annotated coding sequences (CDS) information within the MAG.fa sequences, you can import an annotation-generated .gff file* as well.\nAdditionally, you will require the .bam files containing coverage value information resulting from the application of samtools and the .bam.bai file generated by samtools index. Once all these files are imported, the visualization will display information on CDS in the reference sequence, the location of mapping of metatranscriptomic sequence reads, and the count of metatranscriptomic reads mapped at each position.*Note: The creation of a .gff (General Feature Format) file for MAG.fa can be referred to in the metagenome SOP.\n\n\n\nVisualization of alignment result using IGV program# download prodigal from https://github.com/hyattpd/Prodigal/wiki/installation\n# install prodigal\n$ cd prodigal/\n$ make install\n# run prodigal\n$ prodigal -i sample_MAG.fa -p meta -a sample_MAG.prodigal.faa -d sample_MAG.prodigal.fna -f gff -o sample_MAG.prodigal.gff \n\nUsing Bedtools, you can obtain coverage (count) information for each CDS (coding sequence) in functional annotations. Before applying Bedtools, it is advisable to simplify the .gff entries to include only the essential information for Bedtools usage.\nYou can utilize the ParseGFFonlyCDS.R R script to parse the comprehensive .gff file obtained from functional annotation, extracting only the CDS information, CDS location, and locus tag information to create a simplified .gff file.#make CDS only gff file with python-script\n$ wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/ParseGFFonlyCDS.R \n$ Rscript ParseGFFonlyCDS.R -i sample_MAG.prodigal.gff -o MAG.CDS.gff\n\nThe Bedtools’ bamtobed command converts the bam file into a bed file, and the bedtools coverage command is used to derive count values based on entries in the gff file from the bed file. By matching the location information of CDS entries in the gff file with the locations where sequence reads from the bed file are mapped, you can calculate the count values for each CDS.\nThe resulting bed file includes information about CDS locations, counts of sequence reads mapped to each CDS, and information about the strand direction, in the case of genes (as shown in the example below, denoted as sample.cov).#install bedtools\n$ tar -zxvf bedtools-2.29.1.tar.gz\n$ cd bedtools2\n#alignment\n$ bedtools bamtobed –i sample.bam > sample.bed\n$ bedtools coverage –a MAG.CDS.gff –b sample.bed –s > sample.cov\n\n\n\nExample bed file generated as a result of read alignment","type":"content","url":"/alignment-1","position":1},{"hierarchy":{"lvl1":"Differential (transcriptional) expression analysis"},"type":"lvl1","url":"/de-analysis-1","position":0},{"hierarchy":{"lvl1":"Differential (transcriptional) expression analysis"},"content":"\n\n\n\n*To perform the following analysis, you should have the same gene set.\n\nBy using metatranscriptomic data from different environmental conditions, you can analyze the differences in gene expression based on the specific environmental conditions and obtain information on which genes are up- or down-regulated in each condition. To achieve this, DESeq2 is run using count information generated from the alignment results and functional annotation locus tags.\nHowever, for DESeq2 to work, you need count information and input files for each sample’s metadata.\nThe metadata information can be used in DEG (Differentially Expressed Gene) analysis and various visualization steps.#Download FormatDESeqInput.py\n$wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/coverage.R\n#make DESeq2 input file\n$Rscript coverage.R –r $sample \n#Outputs a result corresponding to the sample keyword\n\nmake design sheet(text파일 생성)File name: Design_Sheet.txt  \n\nSample\n\nCondition\n\ncov1\n\nControl group\n\ncov2\n\nControl group\n\ncov3\n\nExperimental group\n\ncov4\n\nExperimental group\n\nThe following DESeq2 code allows you to obtain normalized count values for each gene and DESeq results from comparisons between groups. Genes with a Log2 Fold Change > 1 or < -1 and a p-value < 0.05 are selected. This information enables you to assess differences in gene expression between different environments and explore the similarity between samples, such as PCoA and α-diversity based on each RNA sample. You can visualize this data through clustering, PCoA plots, and other visual representations.#install DESeq2 package\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"DESeq2\")#DESeq2 running\n#R script download\n$wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/RunDESeq_flow.R\n$ Rscript RunDESeq_flow.R –i $sample.count –d Design_sheet.txt –o output_directory     \n\n\n\nExample of output file using RunDESeq_flow.R\n\n\n\nExample of results using RunDESeq_flow.R\n\nMoreover, you can utilize R packages to visualize information related to gene expression, including normalized count data, Log2 Fold Change, and p-values, through visualizations like heatmaps and volcano plots.","type":"content","url":"/de-analysis-1","position":1},{"hierarchy":{"lvl1":"Metaproteomic analysis tools"},"type":"lvl1","url":"/installation-2","position":0},{"hierarchy":{"lvl1":"Metaproteomic analysis tools"},"content":"Sequencing reads trimming\n\nFastQC, cutadapt, trimGalore\n\nAlignment\n\nBowtie2\n\nConvert file (file format: sam to cov)\n\nSamTools, bedtools\n\nFunctional annotation\n\neggNOG-mapper\n\nVisualization\n\niPATH3, KEGG-mapper, IGV\n\nR package\n\nRiboseqR, DESeq2, pheatmap, ggplot2\n\n\n\nMetaproteomics analysis pipeline","type":"content","url":"/installation-2","position":1},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl2":"Installation"},"type":"lvl2","url":"/installation-2#installation","position":2},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl2":"Installation"},"content":"Before proceeding with the analysis pipeline, let me first explain the program installation process.","type":"content","url":"/installation-2#installation","position":3},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl3":"Install conda environment","lvl2":"Installation"},"type":"lvl3","url":"/installation-2#install-conda-environment","position":4},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl3":"Install conda environment","lvl2":"Installation"},"content":"Conda offers the advantage of creating virtual environments, allowing for independent program installations and management. This feature is particularly valuable as it significantly reduces the risk of program conflicts. Therefore, it is recommended to install Conda-compatible programs via Conda.# set up conda environment (name and python version are set by user)\n$ conda create --name NGS python=3.7\n# active conda environment\n$ conda activate NGS\n# install program for conda \n$ conda install cutadapt\t\t\t\t#cutadapt install\n$ conda install humann –c biobakery3\t\t#humann install\n# download database\n$ humann_databases --download chocophlan full $INSTALL_LOCATION --update-config yes\n$ humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION --update-config yes\n$ humann_databases --download utility_mapping full $INSTALL_LOCATION --update-config yes\n$ conda install bowtie2\t\t\t\t#bowtie2 install\n$ make\n$ conda install cdhit","type":"content","url":"/installation-2#install-conda-environment","position":5},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl3":"Install program","lvl2":"Installation"},"type":"lvl3","url":"/installation-2#install-program","position":6},{"hierarchy":{"lvl1":"Metaproteomic analysis tools","lvl3":"Install program","lvl2":"Installation"},"content":"However, it’s important to note that some programs may still require manual installation. In such cases, you need to install these programs directly. For programs installed separately, you may also need to edit your bash_profile file to add the program and database directories to your system’s $PATH for proper functionality.# create and specify installation folders\n$ mkdir program\n$ cd program\n# SAMtools install\n$ tar -xvf samtools.zip\n$ cd samtools\n$ ./configure -prefix==/where/to/install\n$ make\n$ make install\n# install prodigal\n$ cd prodigal/\n$ make install\n#install bedtools\n$ tar -zxvf bedtools-2.29.1.tar.gz\n$ cd bedtools2\n# download eggnog-mapper from https://github.com/eggnogdb/eggnog-mapper/releases/latest\n$ tar -xvzf eggnog_mapper_(version).tar.gz\n# download eggnog-mapper database\n$ download_eggnog_data.py\n#install SPAdes\n$wget http://cab.spbu.ru/files/release3.15.3/SPAdes-3.15.3-Linux.tar.gz\n$tar -xzf SPAdes-3.15.3-Linux.tar.gz\n$cd SPAdes-3.15.3-Linux/bin/","type":"content","url":"/installation-2#install-program","position":7},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis"},"type":"lvl1","url":"/introduction-2","position":0},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis"},"content":"","type":"content","url":"/introduction-2","position":1},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis","lvl2":"Introduction to Metaproteome"},"type":"lvl2","url":"/introduction-2#introduction-to-metaproteome","position":2},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis","lvl2":"Introduction to Metaproteome"},"content":"Transcriptomics and proteomics analyses provide more accurate information about the biological factors of microorganisms within an ecosystem. In microbiome research, both metatranscriptomics and metaproteomics help in the precise functional analysis of microbial communities that form clusters.\nWhile metatranscriptomic data offer insights into the expression and activity of genes in the environment, metaproteomic information includes protein expression and regulation data. As a result, metaproteomic data can differ from metatranscriptomic data.\nIn metaproteomics, mass spectrometry is used to analyze the proteins within microbial communities. This involves the extraction of proteins from a microbial community, separation of proteins using liquid chromatography (LC), and detection of proteins using tandem mass spectrometry to identify each protein.\nEfforts have been made to improve protein specificity by using high-performance mass spectrometry and developing sophisticated chromatography methods for protein separation. However, it’s important to note that traditional mass spectrometry-based metaproteomic analysis has limitations. Only a fraction of the microbiome sample can be profiled, and low molecular weight proteins are less likely to be detected compared to high molecular weight proteins. Additionally, the frequency of analysis is much lower when compared to metatranscriptomic analysis.\n\n\n\nMulti-omics information-based microbiome functional analysis","type":"content","url":"/introduction-2#introduction-to-metaproteome","position":3},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis","lvl2":"Ribo-sequencing"},"type":"lvl2","url":"/introduction-2#ribo-sequencing","position":4},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metaproteome Analysis","lvl2":"Ribo-sequencing"},"content":"Ribo-seq is a protein analysis technique that applies sequencing technology to study the ribosome-protected mRNA sequences.\nIn this method, cells are treated with chloramphenicol to fix their state, and MNase is used to remove DNA and RNA that are not protected by ribosomes.\nThe sequencing is then performed on the mRNA sequences actively involved in protein synthesis.\nRibo-seq was introduced in 2009 in a Science publication and has since been used to profile ribosomes \n\n[ref].\nIt has been employed to investigate how protein synthesis changes in yeast under different nutritional conditions, such as rich and depleted states.\nRibo-seq allows the quantification of protein synthesis by encrypting the genes responsible for ongoing protein production.\nThis technique provides insights into gene information encoding the proteins being synthesized, allowing for accurate quantification of protein synthesis.\nFurthermore, Ribo-seq has been reported to produce reliable metaproteomic analysis results when applied to fecal samples preserved in RNALater, making it a valuable tool for metaproteomic analysis in various settings.\n\n\n\nMetaRibo-seq을 포함한 마이크로바이옴 분석 workflow ; \n\n[ref]\n\n\n\nRibosome profiling workflow ; \n\n[ref]","type":"content","url":"/introduction-2#ribo-sequencing","position":5},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"type":"lvl1","url":"/preprocessing-2","position":0},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"content":"","type":"content","url":"/preprocessing-2","position":1},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Preprocessing of the sequencing reads"},"type":"lvl2","url":"/preprocessing-2#preprocessing-of-the-sequencing-reads","position":2},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads","lvl2":"Preprocessing of the sequencing reads"},"content":"\n\nPreprocessing of sequencing reads\n\nRibosome-bound mRNA reads differ from the mRNA extracted using the metatranscriptome SOP in that they have shorter RNA fragment lengths, requiring a different analysis approach.\nWhile trimming and alignment (mapping) are conducted following the methods specified in the metatranscriptome SOP, there are differences in the subsequent analysis methods.\nTo utilize raw sequence data for analysis, it’s necessary to go through a process of removing low-quality bases and eliminating adaptors. This process results in enhanced sequence quality and an increased mapping rate.\nThe Kneaddata program makes it easy to remove adaptor sequences used in Illumina platform-based sequencing and host genome sequences.#host RNA removal and trimming\n$ kneaddata --input sample_1.fastq.gz --input sample_2.fastq.gz --reference-db hg37dec_v0.1 --output ./1.Trim/sample --trimmomatic /where/to/Trimmomatic-0.36/ --trimmomatic-options=\"MINLEN:90\" \n#--trimmomatic option; trimmomatic path\n\nYou can use the FastQC program to compare the quality of sequence reads before and after preprocessing, allowing you to verify the trimming results. FastQC provides comprehensive information about the fastq files, including parameters such as per base sequence quality, per sequence QC content, per sequence quality score, sequence length distribution, and more, to assess the outcomes of trimming.#FastQC running(java script)\n$./fastqc\n#check fastq file with java\n\n\n\nExample of quality check results of raw sequence with FastQC","type":"content","url":"/preprocessing-2#preprocessing-of-the-sequencing-reads","position":3},{"hierarchy":{"lvl1":"Reads-based profiling"},"type":"lvl1","url":"/read-based-2","position":0},{"hierarchy":{"lvl1":"Reads-based profiling"},"content":"Apart from eggNOG-mapper, you can also obtain information about metabolic pathways using \n\nHUMAnN.\n\nHUMAnN (HMP Unified Metabolic Analysis Network) is a software designed to profile microbial metabolism and molecular functions from metagenomic or metatranscriptomic sequence data.\nIt accepts various types of input files, including .fastq files from metagenomes or metatranscriptomes after host data removal and quality trimming, alignment result files (.sam or .bam), and gene information with count data in .tsv and .biom formats.\nYou can perform microbial community analysis and functional analysis within the community using pangenome databases such as MetaPhlAn and ChocoPhlAn. Additionally, you can acquire genome information and pathway details using UniRef, MetaCyc, and MinPath.# download humann\n$ conda create --name biobakery3 python=3.7\n$ conda activate biobakery3\n$ conda install humann –c biobakery3\n# download database\n$ humann_databases --download chocophlan full $INSTALL_LOCATION --update-config yes\n$ humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION --update-config yes\n$ humann_databases --download utility_mapping full $INSTALL_LOCATION --update-config yes\n# paired read concatenation\n$ cat kneaddata.trimmed_paired_1.fastq kneaddata.trimmed_paired_2.fastq > kneaddata.trimmed.fastq\n# running humann\n$ humann --input sample_kneaddata_paired_1.fastq --output $OUTPUT_DIR\n# humann result’s features\n$ humann_join_tables -i $OUTPUT_DIR -o sample_pathcoverage.tsv –-file_name pathcoverage \n$ humann_barplot –-input sample_pathcoverage.tsv –-focal-feature $PATHWAY_NAME –-outfile sample_path\n\nThe explanation related to HUMAnN installation and DB download is described once more.\n\nWhen conducting HUMAnN analysis, you can obtain information about gene families and pathways.\nAmong them, you can use pathway information stored in the sample_pathabundance.tsv and sample_pathcoverage.tsv files to create bar plots, allowing you to visualize the proportion of microorganisms involved in specific pathways.\nHUMAnN generates several files (e.g., bowtie results, diamond results), and you can use these for additional analyses.\n\n\n\nExample of a barplot visualization result of path information derived from HUMAnN results","type":"content","url":"/read-based-2","position":1},{"hierarchy":{"lvl1":"Ribosome profiling"},"type":"lvl1","url":"/ribosome-profiling","position":0},{"hierarchy":{"lvl1":"Ribosome profiling"},"content":"You can obtain results using \n\nplotVisualRibo.R script that utilizes .bam files and results obtained from metagenomic analysis as input files. (Linux environment is recommended)#install RiboseqR\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"RiboseqR\")#ribo-seq running\n#file download in https://github.com/bhattlab/bhattlab_workflows/tree/master/metariboseq\n$ Rscript plotVisualRibo.R final.contigs.fa sample_metariboseq.bam\n\nIn summary, five types of files are generated as a result: “allFSshift.pdf,” “histogram.pdf,” and “plotCDSfilt.pdf” (with three variations for different footprints, i.e., 28, 31, and 35).\n\n\n\nExample of the allFSshift.pdf file generated by the plotVisualRibo.R results\n\nRegarding the “allFSshift.pdf” results, this file provides frame information and the proportion of each frame for codon periodicity.\nIn the image above (an example from “allFSshift.pdf”), the x-axis represents the footprint (size), and the y-axis represents the number of reads.\nThis information is used as an indicator to predict the periodicity of gene nucleotide sequences in codons. It helps determine how ribosome-bound mRNA footprints are captured based on whether they align with a specific reading frame.\nIt’s important to note that the results of this periodicity may exhibit different patterns among microbial species, reflecting variations in their translation mechanisms.\n\n\n\nExample of the histogram.pdf(left) and plotCDSfilt.pdf(right) file generated by the plotVisualRibo.R results\n\nThe Histogram.pdf results in a graph that shows the length of reads and the alignment rate, allowing you to determine if there are a significant number of reads of specific lengths and the proportion of those reads in the dataset.\nThe plotCDSfilt.pdf files are generated for ribosome footprint sizes of 28, 31, and 35, resulting in three PDF files.\nIn contrast to RNA-seq results, ribo-seq results exhibit strong signals at the start codon and stop codon. This phenomenon is related to the characteristics of ribosomes during mRNA translation.\nRibosomes spend a longer time recognizing mRNA and preparing for translation during the start codon recognition phase, and the same happens at the stop codon when translation terminates.\nThis leads to the strong signals observed at the start and stop codons.\n\nBy using this information, you can obtain the count values for ribosome-bound mRNA. These count values provide information about the location of ribosomes and their proportions during translation.\nUtilizing this ribosome information, you can indirectly gather insights related to protein synthesis.\nHowever, analyzing ribosome-bound mRNA information alongside transcriptome data often yields more comprehensive and insightful results.\n\n\n\nPredicted translation efficiency; \n\n[ref]","type":"content","url":"/ribosome-profiling","position":1},{"hierarchy":{"lvl1":"Sequencing"},"type":"lvl1","url":"/sequencing-2","position":0},{"hierarchy":{"lvl1":"Sequencing"},"content":"Ribosome profiling (Ribo-seq) requires a specialized sample preparation protocol that differs significantly from standard RNA-seq. Rather than capturing total mRNA, this technique isolates ribosome-protected mRNA fragments (ribosome footprints), which represent mRNAs that are actively being translated into proteins at the moment of sample collection. The key steps involve cell lysis under conditions that arrest ribosomes on mRNA (using chloramphenicol), nuclease digestion to degrade unprotected RNA, size-selection of ribosome-bound fragments via gel filtration chromatography, and subsequent library preparation for Illumina sequencing. This chapter provides the complete wet-lab protocol from fecal sample processing through sequencing, with particular attention to the preparation of stock solutions containing translation-arrest reagents and the micrococcal nuclease (MNase) digestion conditions that determine footprint quality.","type":"content","url":"/sequencing-2","position":1},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Biological Samples"},"type":"lvl2","url":"/sequencing-2#biological-samples","position":2},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Biological Samples"},"content":"As with metatranscriptomic protocols, immediate RNA stabilization is critical for Ribo-seq. RNAlater preserves the ribosome–mRNA complexes in their native translational state, preventing post-collection changes in ribosome occupancy that would distort the resulting translational profile. Samples must be processed promptly and stored at -80°C to maintain the integrity of ribosome-protected fragments.\n\nProcess 500 µL of RNAlater (Ambion) for every 1 g of fecal sample and store it at -80°C","type":"content","url":"/sequencing-2#biological-samples","position":3},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl2","url":"/sequencing-2#ribosome-bound-mrna-prep","position":4},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Ribosome-bound mRNA prep"},"content":"The core of Ribo-seq lies in isolating ribosome-protected mRNA fragments (footprints) of approximately 28–35 nucleotides. This is achieved through a multi-step process: (1) cell lysis in the presence of chloramphenicol to arrest ribosomes at their translational positions, (2) micrococcal nuclease (MNase) digestion to degrade all RNA not physically shielded by a ribosome, and (3) size-selection of monosome-associated fragments via Sephacryl S400 gel filtration columns. The resulting footprints directly correspond to the positions and density of actively translating ribosomes, providing a quantitative readout of protein synthesis that complements but is distinct from total mRNA abundance measured by RNA-seq.","type":"content","url":"/sequencing-2#ribosome-bound-mrna-prep","position":5},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Reagents","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl3","url":"/sequencing-2#reagents","position":6},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Reagents","lvl2":"Ribosome-bound mRNA prep"},"content":"RLT buffer (Qiagen), β-mercaptoethanol, Superase-In 20U/μL, 100% ethanol, 3M sodium acetate, chloramphenicol 50mg/ml, 1M Tris-HCl (pH8.0), 1M NH4Cl, 1M MgOAc, RNase-free water, Ipecal CA-630, 1M MgCl2, 0.5M EGTA, 5M NaCl, MNase (NEB), 0.5M CaCl2, Qiazol (Qiagen), chloroform\n\nkit\nmiRNeasy mini kit (Qiagen), TURBO DNA-free™ Kit (Ambion)","type":"content","url":"/sequencing-2#reagents","position":7},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Equipment","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl3","url":"/sequencing-2#equipment","position":8},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Equipment","lvl2":"Ribosome-bound mRNA prep"},"content":"FastPrep-24™ 5G, pipette, aerosol barrier pipette tips, microcentrifuge, 1mm zirconia/silica beads, Sephacryl S400 Microspin columns (Sigma-Aldrich)Optional; Qubit fluorometer (Thermo Fisher Scientific), Fragment analyzer","type":"content","url":"/sequencing-2#equipment","position":9},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Stock solutions","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl3","url":"/sequencing-2#stock-solutions","position":10},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Stock solutions","lvl2":"Ribosome-bound mRNA prep"},"content":"stock solution A\n\nvolume\n\nRLT buffer(Qiagen)\n\n965 μL\n\nβ-mercaptoethanol\n\n10 μL\n\nSuperase-In, 20U/μL\n\n15 μL\n\nChloramphenicol, 50mg/ml\n\n10 μL\n\nTotal\n\n1 ml\n\nstock solution B\n\nvolume\n\nTris-HCl, pH 8.0,  1M\n\n25 μL\n\nNH4Cl, 1M\n\n25 μL\n\nMgOAc, 1M\n\n10 μL\n\nChloramphenicol, 50mg/ml\n\n10 μL\n\nRNase-free water\n\n930 μL\n\nTotal\n\n1 ml\n\nstock solution C\n\nvolume\n\nIpegal CA-630\n\n100 μL\n\nMgCl2, 1M\n\n500 μL\n\nEGTA 0.5M\n\n500 μL\n\nNaCl, 5M\n\n500 μL\n\nTris-HCl, pH 8.0, 1M\n\n500 μL\n\nRNase-free water\n\n7.9 ml\n\nTotal\n\n10 ml","type":"content","url":"/sequencing-2#stock-solutions","position":11},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Ribosome-bound mRNA preparation","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl3","url":"/sequencing-2#ribosome-bound-mrna-preparation","position":12},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Ribosome-bound mRNA preparation","lvl2":"Ribosome-bound mRNA prep"},"content":"Place a fecal sample and beads in each screw-top tube.\n| Each tube | volume |\n| ---| --- |\n| Fecal sample | 150mg |\n| 1.0mm zirconia/silica beads | ~20 |\n| Stock solution A | 600 μL |\n\nPerform two rounds of MP FastPrep at 6.0 m/s for 40 seconds each.\n\nCentrifuge at 12,000 rpm for 3 minutes, and transfer 500 μL of the supernatant to a new e-tube.\n\nAdd 50 μL of 3M sodium acetate and 1 mL of 100% ethanol to the supernatant.\n\nIncubate on ice (or at 4°C) for 30 minutes.\n\nCentrifuge at 12,000 rpm at 4°C for 30 minutes, and discard the supernatant.\n\nRe-suspend in 100 μL of Stock solution B.\n\nDilute RNA 1/50 and measure RNA concentration with a Qubit.\n\nIncubate with MNase for 2 hours.\n| Total  | 200μL |\n| ---| --- |\n| Lysate | 80 μg |\n| 0.5M CaCl2 | 2 μL |\n| Superase-In (20U/μL) | 2 μL |\n| NEB MNase (500U/μL) | 1 μL |\n| RNase free water | To 200 μL |\n\nAdd 2.5 μL of 0.5M EGTA to stop the reaction.\n\nPrepare a Sephacryl S400 MicroSpin column and re-suspend the resin inside the column.\n\nCentrifuge the column at 600 rpm for 1 minute, discard the flow-through.\n\nAdd 500 μL of Stock solution C to the column, centrifuge at 600 rpm at 4°C for 1 minute, and discard the flow-through (repeat this step).\n\nAdd 500 μL of Stock solution C to the column, centrifuge at 600 rpm at 4°C for 4 minutes, and transfer the column to a new e-tube.\n\nAdd 100 μL of the MNase reaction mixture (from step 10) to each column, centrifuge at 600 rpm for 2 minutes, and collect the flow-through.\n\nAdd 700 μL of Qiazol to the collected flow-through, vortex, and incubate at room temperature for 5 minutes.\n\nAdd 140 μL of chloroform, shake for 15 seconds, and incubate at room temperature for 3 minutes.\n\nCentrifuge at 12,000 rpm at 4°C for 15 minutes, and transfer the upper phase to a new e-tube.\n\nAdd approximately 525 μL (1.5 times the upper phase volume) of 100% ethanol to the upper phase and mix by pipetting. *\n\nLoad the solution from step * onto an RNeasy mini column and centrifuge at 12,000 rpm for 15 seconds to discard the flow-through.\n\nRepeat previous step with the remaining solution from step *.\n\nAdd 700 μL of RWT buffer to the column, centrifuge at 12,000 rpm for 15 seconds to discard the flow-through.\n\nAdd 500 μL of RPE buffer to the column, centrifuge at 12,000 rpm for 15 seconds to discard the flow-through.\n\nAdd 500 μL of RPE buffer to the column, centrifuge at 12,000 rpm for 2 minutes to discard the flow-through. Then, transfer the column to a new e-tube.\n\nAdd 30-50 μL of RNase-free water to the column membrane, centrifuge at 12,000 rpm for 1 minute, and collect the ribosome-bound mRNA.\n\n[Optional: QC]\n\nMeasure the RNA concentration using a Qubit fluorometer*.*A NanoDrop spectrophotometer can also be used, but for accurate concentration measurement, it is recommended to use a Qubit fluorometer.\n\nPerform QC of the obtained RNA using a Fragment analyzer.\n\n\n\nExample of ribosome-bound mRNA sample analysis results using a Fragment analyzer\n\nA Fragment Analyzer can be used to assess the proportion of rRNA in RNA samples, in addition to mRNA. Unlike mRNA prepared for transcriptome analysis, ribosome profiling selectively prepares short mRNA fragments that are associated with ribosomes and small-sized rRNA.\n\nPrepare the 10X TURBO DNase buffer to a 1X concentration and add 1 μL of TURBO DNase to the RNA.\n\nIncubate at 37°C for 20-30 minutes.\n\nAdd 0.1 times the volume of DNase inactivation reagent.\n\nIncubate at room temperature for 5 minutes.\n\nCentrifuge at 10,000 rpm for 1 minute and 30 seconds, and transfer the supernatant to a new e-tube.","type":"content","url":"/sequencing-2#ribosome-bound-mrna-preparation","position":13},{"hierarchy":{"lvl1":"Sequencing","lvl3":"rRNA depletion","lvl2":"Ribosome-bound mRNA prep"},"type":"lvl3","url":"/sequencing-2#rrna-depletion","position":14},{"hierarchy":{"lvl1":"Sequencing","lvl3":"rRNA depletion","lvl2":"Ribosome-bound mRNA prep"},"content":"Even after MNase digestion and monosome purification, ribosomal RNA fragments still constitute a substantial fraction of the remaining RNA pool. Enzymatic rRNA depletion using probe-based kits is therefore essential to enrich for true ribosome footprints and maximize the proportion of informative sequencing reads. Two kits are applied sequentially to target both host-derived and bacterial rRNA species.\n\nHost rRNA remove Illumina TruSeq Stranded Total RNA Library Prep Plant Kit (Illumina, # 20020611)\n\nBacterial rRNA remove Illumina Stranded Total RNA Library Prep with Ribo-Zero Plus kit (Illumina, #20040529)","type":"content","url":"/sequencing-2#rrna-depletion","position":15},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Sequencing"},"type":"lvl2","url":"/sequencing-2#sequencing","position":16},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Sequencing"},"content":"The purified ribosome-protected fragments are converted into a sequencing-ready cDNA library. Because Ribo-seq footprints are characteristically short (28–35 nt), the library preparation preserves these small fragments through careful adapter ligation and limited-cycle PCR amplification, ensuring that the final library accurately represents the size distribution of ribosome footprints.","type":"content","url":"/sequencing-2#sequencing","position":17},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing library preparation","lvl2":"Sequencing"},"type":"lvl3","url":"/sequencing-2#sequencing-library-preparation","position":18},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing library preparation","lvl2":"Sequencing"},"content":"Perform mRNA fragmentation using divalent cations.\n\nFirst strand cDNA synthesis using SuperScript II reverse transcriptase (Invitrogen, #18064014) with random primers.\n\nSecond strand cDNA synthesis using DNA Polymerase I, RNase H, and dUTP.\n\nPerform end repair on synthesized cDNA fragments, followed by the attachment of a single ‘A’ base and adaptor ligation.\n\nPerform PCR to create the cDNA library for sequencing.*Progress Sequencing library quantificationKAPA Library Quantificatoin kits for Illumina Sequecing platforms according to the qPCR Quantification Protocol Guide (KAPA BIOSYSTEMS, #KK4854)*Conduct quality control (QC) for the sequencing library.TapeStation D1000 ScreenTape (Agilent Technologies, # 5067-5582)","type":"content","url":"/sequencing-2#sequencing-library-preparation","position":19},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing","lvl2":"Sequencing"},"type":"lvl3","url":"/sequencing-2#sequencing-1","position":20},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing","lvl2":"Sequencing"},"content":"Perform paired-end (2×150 bp) sequencing on an Illumina NovaSeq (Illumina) instrument using the final indexed sequencing library.","type":"content","url":"/sequencing-2#sequencing-1","position":21},{"hierarchy":{"lvl1":"Small protein prediction"},"type":"lvl1","url":"/small-protein-prediction","position":0},{"hierarchy":{"lvl1":"Small protein prediction"},"content":"\n\n\n\nRibosome profiling analysis allows obtaining information about small proteins that may not be accessible through genome or transcriptome analysis.\nSmall proteins refer to proteins with a size of less than 70 amino acids. These small proteins are known to be associated with the regulation of other genes or key factors in microorganisms, but their functional analysis can be challenging.\nThe goal of this process is to classify small proteins, perform new annotations, and discover previously unannotated genes with new functions.\nTo start, it’s necessary to filter genes from DNA sequence files obtained through prodigal, which are less than 70 amino acids.\nUsing Linux, you can create a file containing only the small protein genes by employing awk and conditional statements. In most cases, these small, separated proteins correspond to hypothetical proteins.# run prodigal \n$ prodigal -i sample_MAG.fa -p meta -a sample_MAG.prodigal.faa -d sample_MAG.prodigal.fna -f gff -o sample_MAG.prodigal.gff\n# small amino acid filtering\n$ awk '/^>/ {if (length(seq) <= 210) {print header; print seq} } {if (/^>/) {header = $0; seq = \"\"} else {seq = seq $0}} END {if (length(seq) <= 10) {print header; print seq}}' sample_MAG.prodigal.ffn > MAG_smallprotein.fnn\n# run CD-hit for clustering\n$ cd-hit -i MAG_smallprotein.ffn -o example -n 2 -p 1 -c 0.5 -d 200 -M 50000 -l 5 -s 0.95 -aL 0.95 -g 1\n\nAfter this initial filtering, you can proceed to determine whether these small proteins have similar functions or if they represent new small proteins. To do this, you can use CD-HIT to cluster these proteins.\nCD-HIT groups genes with similar sequences, generating files composed of representative sequences for each cluster.\n\nFollowing the clustering step, you can use RNAcode to analyze and obtain information about the protein coding regions of the genes.\nRNAcode requires an alignment file as input, so you can align the DNA sequences from the CD-HIT results using a tool like ClustalW.\nThe DNA sequence alignment file can then be used for analysis with RNAcode, allowing you to infer the coding sequences of small proteins.\nAdditionally, you can use read alignment information to obtain data on the expression of these small proteins.# alignment multiple sequence\n$ clustalw output\n# run RNAcode\n$ RNAcode output.aln --outfile results.gtf --gtf --best-only --cutoff 0.01 --eps data.aln","type":"content","url":"/small-protein-prediction","position":1},{"hierarchy":{"lvl1":"Translational expression profiling"},"type":"lvl1","url":"/translational-quantification","position":0},{"hierarchy":{"lvl1":"Translational expression profiling"},"content":"\n\n\n\nRibo-seq read alignment results provide information for assessing the expression levels of individual genes.\nFurthermore, it is possible to obtain expression information for individual contigs or MAGs generated from de novo assembly results of the metagenome.\nIn some cases, for more systematic analysis, it may be necessary to categorize genes with similar functions or group genes involved in specific metabolic pathways to analyze their expression levels.\nTo accomplish this, annotation information for each CDS in functional databases is required.\nThe \n\neggNOG-mapper can be used to easily obtain this information. eggNOG-mapper requires an input file in which the amino acid sequences of each gene are listed in a .faa file format.\nWhen running with default options, eggNOG-mapper uses BLAST to find the most similar information for each gene’s amino acid sequence, extracting data related to \n\nCOG(Clusters of Orthologous Groups), \n\nKEGG(Kyoto Encyclopedia of Genes and Genomes), \n\nCAZy(Carbohydrate-Active EnZymes), and \n\nPfam.# download eggnog-mapper from https://github.com/eggnogdb/eggnog-mapper/releases/latest\n$ tar -xvzf eggnog_mapper_(version).tar.gz\n# download eggnog-mapper database\n$ download_eggnog_data.py\n# run eggnog-mapper\n$ emapper.py (option) -i sample_MAG.prodigal.faa -o sample_MAG.eggnog.out\n\nThe resulting files include eggnog.out.hit, eggnog.out.annotation, and eggnog.out.seed_ortholog, with eggnog.out.annotation containing annotation information from various databases such as COG and KEGG.\n\n\n\nExample of an announcement file among EGGNOG-mapper results\n\nUsing the COG information obtained from EGGNOG-mapper results, it is possible to predict the expression levels of each COG functional category across the entire metatranscriptome.\n\n\n\nExample of COG distribution\n\nAdditionally, the extracted COG or KEGG ORTHOLOGY information can be visualized using tools like KEGG mapper, \n\nIPATH3, allowing for the exploration of the overall correlations among highly expressed genes. Depending on the options chosen, you can select a few genes with high count values, adjust line thickness based on count (i.e., expression level), or use different colors for each MAG, among other possibilities, to obtain diverse results.\n\n\n\nExample of iPATH3 results","type":"content","url":"/translational-quantification","position":1},{"hierarchy":{"lvl1":"Reads alignment"},"type":"lvl1","url":"/alignment","position":0},{"hierarchy":{"lvl1":"Reads alignment"},"content":"\n\n\n\nWe would like to introduce the “reference-guided analysis” method, which is based on mapping RNA-seq reads to the sequences of de novo assembled contigs and metagenome-assembled genomes (MAGs) obtained from metagenome analysis.\n\n\n\n\n\nIn this approach, after pre-processing, where fastq files are processed to enhance sequence quality, alignment is performed by mapping the reads to the reference sequences*. The STAR program is utilized to create the reference file and perform the mapping of reads to the generated reference sequences.\n\nTypes of Reference Sequences\n1.Final.contig.fa obtained from metagenome de novo assembly pipeline analysis.\n\nMAG.fa obtained from metagenome MAG binning results.#building STAR index\n$ STAR --runMode genomeGenerate --genomeSAindexNbases 10 --runThreadN 8 --genomeDir ./index/sample --genomeFastaFiles sample_MAG.fa \n#mapping\n$ STAR --genomeDir ./index/sample --runThreadN 8 --readFilesIn ./1.Trim/sample_kneaddata_paired_1.fastq ./1.Trim/sample_kneaddata_paired_2.fastq --outFileNamePrefix ./2.Align/sample_\n\nBy utilizing the STAR runMode command, index files for STAR running are generated from the MAG.fa file of the metagenome. These created index files serve as a basis for mapping reads to reference sequences, resulting in a .sam file where information about gene counts is assigned to each gene.\nThe STAR alignment results are not output separately but are stored in the final.out file. The results of read alignment can be verified using the Log.final.out file, which provides information about the total unique reads, multi-mapping reads, and unmapped reads. Due to the large size of the STAR-generated .sam files, they are converted into smaller-sized binary format .bam files.To align the mapping information after read mapping, the samtools’ view and sort functions are utilized to transform the .sam files into .bam files.#install samtools\n$ tar -xvf samtools.zip\n$ cd samtools\n$ ./configure -prefix==/where/to/install\n$ make\n$ make install\n#sam file sorting and indexing\n$ samtools view -b -F 4 sample_Aligned.out.sam | samtools sort - > sample.bam\n$ samtools index sample.bam\n\nOnce these .bam files are generated, you can visualize the alignment results using the IGV program. To examine the alignment results with the IGV program, you will need the MAG.fa obtained from metagenome de novo assembly or MAG results. If you wish to display annotated coding sequences (CDS) information within the MAG.fa sequences, you can import an annotation-generated .gff file* as well.\nAdditionally, you will require the .bam files containing coverage value information resulting from the application of samtools and the .bam.bai file generated by samtools index. Once all these files are imported, the visualization will display information on CDS in the reference sequence, the location of mapping of metatranscriptomic sequence reads, and the count of metatranscriptomic reads mapped at each position.*Note: The creation of a .gff (General Feature Format) file for MAG.fa can be referred to in the metagenome SOP.\n\n\n\nVisualization of alignment result using IGV program# download prodigal from https://github.com/hyattpd/Prodigal/wiki/installation\n# install prodigal\n$ cd prodigal/\n$ make install\n# run prodigal\n$ prodigal -i sample_MAG.fa -p meta -a sample_MAG.prodigal.faa -d sample_MAG.prodigal.fna -f gff -o sample_MAG.prodigal.gff \n\nUsing Bedtools, you can obtain coverage (count) information for each CDS (coding sequence) in functional annotations. Before applying Bedtools, it is advisable to simplify the .gff entries to include only the essential information for Bedtools usage.\nYou can utilize the ParseGFFonlyCDS.R R script to parse the comprehensive .gff file obtained from functional annotation, extracting only the CDS information, CDS location, and locus tag information to create a simplified .gff file.#make CDS only gff file with python-script\n$ wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/ParseGFFonlyCDS.R \n$ Rscript ParseGFFonlyCDS.R -i sample_MAG.prodigal.gff -o MAG.CDS.gff\n\nThe Bedtools’ bamtobed command converts the bam file into a bed file, and the bedtools coverage command is used to derive count values based on entries in the gff file from the bed file. By matching the location information of CDS entries in the gff file with the locations where sequence reads from the bed file are mapped, you can calculate the count values for each CDS.\nThe resulting bed file includes information about CDS locations, counts of sequence reads mapped to each CDS, and information about the strand direction, in the case of genes (as shown in the example below, denoted as sample.cov).#install bedtools\n$ tar -zxvf bedtools-2.29.1.tar.gz\n$ cd bedtools2\n#alignment\n$ bedtools bamtobed –i sample.bam > sample.bed\n$ bedtools coverage –a MAG.CDS.gff –b sample.bed –s > sample.cov\n\n\n\nExample bed file generated as a result of read alignment","type":"content","url":"/alignment","position":1},{"hierarchy":{"lvl1":"Differential (transcriptional) expression analysis"},"type":"lvl1","url":"/de-analysis","position":0},{"hierarchy":{"lvl1":"Differential (transcriptional) expression analysis"},"content":"\n\n\n\n*To perform the following analysis, you should have the same gene set.\n\nBy using metatranscriptomic data from different environmental conditions, you can analyze the differences in gene expression based on the specific environmental conditions and obtain information on which genes are up- or down-regulated in each condition. To achieve this, DESeq2 is run using count information generated from the alignment results and functional annotation locus tags.\nHowever, for DESeq2 to work, you need count information and input files for each sample’s metadata.\nThe metadata information can be used in DEG (Differentially Expressed Gene) analysis and various visualization steps.#Download FormatDESeqInput.py\n$wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/coverage.R\n#make DESeq2 input file\n$Rscript coverage.R –r $sample \n#Outputs a result corresponding to the sample keyword\n\nmake design sheet(text파일 생성)File name: Design_Sheet.txt  \n\nSample\n\nCondition\n\ncov1\n\nControl group\n\ncov2\n\nControl group\n\ncov3\n\nExperimental group\n\ncov4\n\nExperimental group\n\nThe following DESeq2 code allows you to obtain normalized count values for each gene and DESeq results from comparisons between groups. Genes with a Log2 Fold Change > 1 or < -1 and a p-value < 0.05 are selected. This information enables you to assess differences in gene expression between different environments and explore the similarity between samples, such as PCoA and α-diversity based on each RNA sample. You can visualize this data through clustering, PCoA plots, and other visual representations.#install DESeq2 package\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"DESeq2\")#DESeq2 running\n#R script download\n$wget https://raw.githubusercontent.com/sujin9819/ngs/main/R_scripts/RunDESeq_flow.R\n$ Rscript RunDESeq_flow.R –i $sample.count –d Design_sheet.txt –o output_directory     \n\n\n\nExample of output file using RunDESeq_flow.R\n\n\n\nExample of results using RunDESeq_flow.R\n\nMoreover, you can utilize R packages to visualize information related to gene expression, including normalized count data, Log2 Fold Change, and p-values, through visualizations like heatmaps and volcano plots.","type":"content","url":"/de-analysis","position":1},{"hierarchy":{"lvl1":"Transcript de novo assembly"},"type":"lvl1","url":"/denovo-assembly-1","position":0},{"hierarchy":{"lvl1":"Transcript de novo assembly"},"content":"In addition to the reference-guided approach, there is valuable information that can be obtained through a reference-independent analysis in metagenome analysis.\nPerforming de novo assembly using metatranscriptomic data allows for the extraction of (putative) transcriptional segment information.\n\nThe program used for assembly is called SPAdes, which supports various types of data, and the command options vary depending on the input data.\nWhen working with metagenome data, metaSPAdes (or --meta) is used, while rnaSPAdes is employed for de novo assembly using RNA-seq reads.\nIt’s worth noting that SPAdes can be used for a wide range of input data types, including plasmid, metaplasmid, RNA virus data, and more.#install SPAdes\n$wget http://cab.spbu.ru/files/release3.15.3/SPAdes-3.15.3-Linux.tar.gz\n$tar -xzf SPAdes-3.15.3-Linux.tar.gz\n$cd SPAdes-3.15.3-Linux/bin/\n#SPAdes running\n#RNA single ends\n$spades.py –-rna –s single_end_trimmed.fastq –o sample\n#RNA paired ends\n$spades.py –-rna –1 forward_trimmed.fastq -2 reverse_trimmed.fastq –o sample","type":"content","url":"/denovo-assembly-1","position":1},{"hierarchy":{"lvl1":"Transcriptional expression profiling"},"type":"lvl1","url":"/expression-profiling","position":0},{"hierarchy":{"lvl1":"Transcriptional expression profiling"},"content":"\n\n\n\nRNA-seq read alignment results provide information for assessing the expression levels of individual genes.\nFurthermore, it is possible to obtain expression information for individual contigs or MAGs generated from de novo assembly results of the metagenome.\nIn some cases, for more systematic analysis, it may be necessary to categorize genes with similar functions or group genes involved in specific metabolic pathways to analyze their expression levels.\nTo accomplish this, annotation information for each CDS in functional databases is required.\nThe \n\neggNOG-mapper can be used to easily obtain this information. eggNOG-mapper requires an input file in which the amino acid sequences of each gene are listed in a .faa file format.\nWhen running with default options, eggNOG-mapper uses BLAST to find the most similar information for each gene’s amino acid sequence, extracting data related to \n\nCOG(Clusters of Orthologous Groups), \n\nKEGG(Kyoto Encyclopedia of Genes and Genomes), \n\nCAZy(Carbohydrate-Active EnZymes), and \n\nPfam.# download eggnog-mapper from https://github.com/eggnogdb/eggnog-mapper/releases/latest\n$ tar -xvzf eggnog_mapper_(version).tar.gz\n# download eggnog-mapper database\n$ download_eggnog_data.py\n# run eggnog-mapper\n$ emapper.py (option) -i sample_MAG.prodigal.faa -o sample_MAG.eggnog.out\n\nThe resulting files include eggnog.out.hit, eggnog.out.annotation, and eggnog.out.seed_ortholog, with eggnog.out.annotation containing annotation information from various databases such as COG and KEGG.\n\n\n\nExample of an announcement file among EGGNOG-mapper results\n\nUsing the COG information obtained from EGGNOG-mapper results, it is possible to predict the expression levels of each COG functional category across the entire metatranscriptome.\n\n\n\nExample of COG distribution\n\nAdditionally, the extracted COG or KEGG ORTHOLOGY information can be visualized using tools like KEGG mapper, \n\nIPATH3, allowing for the exploration of the overall correlations among highly expressed genes. Depending on the options chosen, you can select a few genes with high count values, adjust line thickness based on count (i.e., expression level), or use different colors for each MAG, among other possibilities, to obtain diverse results.\n\n\n\nExample of iPATH3 results","type":"content","url":"/expression-profiling","position":1},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools"},"type":"lvl1","url":"/installation-1","position":0},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools"},"content":"Sequencing reads trimming\n\nFastQC, cutadapt, trimGalore\n\nAlignment\n\nBowtie2\n\nConvert file (file format: sam to cov)\n\nSamTools, bedtools\n\nFunctional annotation\n\neggNOG-mapper\n\nVisualization\n\niPATH3, KEGG-mapper, IGV\n\nR package\n\nDESeq2, ggplot2, pheatmap\n\n\n\nMetatranscriptomics analysis pipeline","type":"content","url":"/installation-1","position":1},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl2":"Installation"},"type":"lvl2","url":"/installation-1#installation","position":2},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl2":"Installation"},"content":"Before proceeding with the analysis pipeline, let me first explain the program installation process.","type":"content","url":"/installation-1#installation","position":3},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl3":"Install conda environment","lvl2":"Installation"},"type":"lvl3","url":"/installation-1#install-conda-environment","position":4},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl3":"Install conda environment","lvl2":"Installation"},"content":"Conda offers the advantage of creating virtual environments, allowing for independent program installations and management. This feature is particularly valuable as it significantly reduces the risk of program conflicts. Therefore, it is recommended to install Conda-compatible programs via Conda.# set up conda environment (name and python version are set by user)\n$ conda create --name NGS python=3.7\n# active conda environment\n$ conda activate NGS\n# install program for conda \n$ conda install cutadapt\t\t\t\t#cutadapt install\n$ conda install humann –c biobakery3\t\t#humann install\n# download database\n$ humann_databases --download chocophlan full $INSTALL_LOCATION --update-config yes\n$ humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION --update-config yes\n$ humann_databases --download utility_mapping full $INSTALL_LOCATION --update-config yes\n$ conda install bowtie2\t\t\t\t#bowtie2 install\n$ make","type":"content","url":"/installation-1#install-conda-environment","position":5},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl3":"Install program","lvl2":"Installation"},"type":"lvl3","url":"/installation-1#install-program","position":6},{"hierarchy":{"lvl1":"Metatranscriptomic analysis tools","lvl3":"Install program","lvl2":"Installation"},"content":"However, it’s important to note that some programs may still require manual installation. In such cases, you need to install these programs directly. For programs installed separately, you may also need to edit your bash_profile file to add the program and database directories to your system’s $PATH for proper functionality.# create and specify installation folders\n$ mkdir program\n$ cd program\n# SAMtools install\n$ tar -xvf samtools.zip\n$ cd samtools\n$ ./configure -prefix==/where/to/install\n$ make\n$ make install\n# install prodigal\n$ cd prodigal/\n$ make install\n#install bedtools\n$ tar -zxvf bedtools-2.29.1.tar.gz\n$ cd bedtools2\n# download eggnog-mapper from https://github.com/eggnogdb/eggnog-mapper/releases/latest\n$ tar -xvzf eggnog_mapper_(version).tar.gz\n# download eggnog-mapper database\n$ download_eggnog_data.py\n#install SPAdes\n$wget http://cab.spbu.ru/files/release3.15.3/SPAdes-3.15.3-Linux.tar.gz\n$tar -xzf SPAdes-3.15.3-Linux.tar.gz\n$cd SPAdes-3.15.3-Linux/bin/","type":"content","url":"/installation-1#install-program","position":7},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metatranscriptome Analysis"},"type":"lvl1","url":"/introduction-1","position":0},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metatranscriptome Analysis"},"content":"","type":"content","url":"/introduction-1","position":1},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metatranscriptome Analysis","lvl2":"Introduction to Metatranscriptome"},"type":"lvl2","url":"/introduction-1#introduction-to-metatranscriptome","position":2},{"hierarchy":{"lvl1":"Standard Operating Procedure for Next-Generation Sequencing (NGS)-Based Metatranscriptome Analysis","lvl2":"Introduction to Metatranscriptome"},"content":"The term microbiome refers to the concept encompassing a community of microorganisms (microbiota) residing in a particular environment, along with their complete genetic information. Microbiome research traditionally involves the amplification and sequencing of conserved regions of marker genes, such as ribosomal genes, from environmental DNA using PCR, allowing for the identification of the types of microorganisms present in the environment. In contrast, microbiome research utilizes whole DNA sequence analysis, known as metagenome sequencing, which not only identifies the types of microorganisms present in the environment but also enables the exploration of the genetic diversity and functions possessed by these microorganisms. However, metagenomic (metagenome) data can inform about the presence or absence of specific species or genes but cannot determine whether they are active within the microbiome ecosystem, posing limitations.\n\n\n\nMulti-omics information-based microbiome functional analysis\n\nTo investigate how microbial communities respond to environmental changes, metatranscriptome analysis has been initiated, and metatranscriptomic information will play a crucial role in understanding the ecology of the microbiome. Even before the advent of high-throughput DNA sequencing methods, research has been conducted to measure the expression levels of genes of interest using qPCR and to study the expression patterns of known transcripts from specific organisms using microarray technology. With the widespread adoption of Next-Generation Sequencing (NGS) technology, RNA sequencing (RNA-seq) has not only allowed for the measurement of the expression levels of known transcript targets but has also made it possible to obtain information on the entire transcriptome, including previously unknown transcripts and transcript variants, such as non-coding RNAs, in a specific environment. For these reasons, RNA-seq is increasingly prevalent in microbiome research and finds applications in various fields, including gene expression analysis, identification of highly active microbial community members, discovery of regulatory factors, investigation of microbial interactions, and studies on interactions with hosts.\n\nBased on these requirements, RNA-seq is being increasingly utilized in microbiome research. In this Standard Operating Procedure (SOP), we aim to describe reference-guided metatranscriptome analysis and reference-independent metatranscriptome analysis methods based on mapping RNA-seq reads to de novo assembled contigs and metagenome-assembled genomes (MAGs) obtained from metagenomes.\n\n\n\nReference-guided and reference-independent metatranscriptome analysis methods\n\nBefore diving into this comprehensive SOP, various tools that can be utilized for metatranscriptome analysis are introduced. In addition to the tools presented in this SOP, other tools listed in Table 1 or similar tools with similar purposes can be selectively applied at each step.\n\nTable 1. List of available RNA-seq analysis tools\n\nCategory\n\nTools\n\nDescription\n\nYear\n\nTrimming\n\ncutadapt\n\n5' adaptor trimming\n\n2011\n\nTrimGalore\n\nWrapper around Cutadapt and FastQCpaired-end trimming\n\n2013\n\ntrimmomatic\n\nPaired-end trimming\n\n2014\n\nAlignment\n\nbowtie2\n\nShort read mapping, local alignment, use FM-index algorithm\n\n2012\n\nBWA\n\nLow-divergent sequences mapping, need genome reference, use BWT and FM index algorithm\n\n2009\n\nHiSat2\n\nHighly useful for human data analysis. Utilized in tasks like Human Leukocyte Antigen (HLA) typing and DNA fingerprinting. Use the FM index.\n\n2019\n\nSTAR\n\nImprove de novo RNA-seq analysis and allow for the mapping of long-read mRNA data.\n\n2013\n\nTopHat2\n\nBowtie-based short read mapping\n\n2013\n\nDE analysis\n\nCuffdiiff2\n\ncufflink-associated tool. utilize sam(bam)file to compare gene and isoform expression\n\n2013\n\nDESeq2\n\nR package, employ shrinkage estimation techniques and utilizes RLE (Relative Log Expression) normalization.\n\n2014\n\nEdgeR\n\nR package, Use raw count value as input file. TMM(Trimmed Mean M-values) normalization ���\n\n2010\n\nlimma\n\nR package. Effective for a small number of samples, using TMM normalization\n\n2015\n\nNOISeq\n\nR package. Using a nonparametric approach and an RPKM/TMM/uppartile normalization approach\n\n2011\n\nSAMSeq\n\nR package. Gene-level DE analysis using sam file as input file. Normalization based on the mean value of the total count\n\n2013\n\nde novo assembly\n\nmegahit\n\nSingle genome assembly, Multiple library analysis is possible\n\n2015\n\nSPAdes\n\nVarious types of data, such as RNA, virus RNA, plasmid, etc., can be assembled. Not only fastq, fasta files but also bam files can be inputted\n\n2012\n\ntrinity\n\nTranscriptome assembler\n\n2011\n\nTaxonomy assignment\n\nkaiju\n\nAnalyze the entire sequence of the meta-genome or the sequence of the meta-transcript using the GenBank protein-redundant database\n\n2016\n\nkraken\n\nTazonomy analysis using GenBank nucleotide non-redundant database\n\n2014\n\nMetaPhlAn\n\nAnalysis of microbial composition from meta-genetic information at species level. Use your own marker genes\n\n2012\n\nonecodex\n\nWeb-based analysis tool using Genome database and targeted loci database\n\n2015\n\nFormat transition\n\nBEDTools\n\nSoftware using bam or bed files. Raw count value can be obtained, but a candidate is required\n\n2010\n\nCufflink\n\nTool that assembles RNA-seq mapping results (sam file) and calculates an unbalance haved FPKM value as result\n\n2010\n\nHTSeq\n\nPython package, calculation of read mapping using gff information\n\n2015\n\nSAMTools\n\nSoftware that converts or sorts sam files\n\n2009","type":"content","url":"/introduction-1#introduction-to-metatranscriptome","position":3},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"type":"lvl1","url":"/preprocessing-1","position":0},{"hierarchy":{"lvl1":"Preprocessing of the sequencing reads"},"content":"\n\nPreprocessing of sequencing reads\n\nTo utilize raw sequence data for analysis, it’s necessary to go through a process of removing low-quality bases and eliminating adaptors. This process results in enhanced sequence quality and an increased mapping rate.\nThe Kneaddata program makes it easy to remove adaptor sequences used in Illumina platform-based sequencing and host genome sequences.#host RNA removal and trimming\n$ kneaddata --input sample_1.fastq.gz --input sample_2.fastq.gz --reference-db hg37dec_v0.1 --output ./1.Trim/sample --trimmomatic /where/to/Trimmomatic-0.36/ --trimmomatic-options=\"MINLEN:90\" \n#--trimmomatic option; trimmomatic path\n\nYou can use the FastQC program to compare the quality of sequence reads before and after preprocessing, allowing you to verify the trimming results. FastQC provides comprehensive information about the fastq files, including parameters such as per base sequence quality, per sequence QC content, per sequence quality score, sequence length distribution, and more, to assess the outcomes of trimming.#FastQC running(java script)\n$./fastqc\n#check fastq file with java\n\n\n\nExample of quality check results of raw sequence with FastQC","type":"content","url":"/preprocessing-1","position":1},{"hierarchy":{"lvl1":"Reads-based profiling"},"type":"lvl1","url":"/read-based-1","position":0},{"hierarchy":{"lvl1":"Reads-based profiling"},"content":"Apart from eggNOG-mapper, you can also obtain information about metabolic pathways using \n\nHUMAnN.\n\nHUMAnN (HMP Unified Metabolic Analysis Network) is a software designed to profile microbial metabolism and molecular functions from metagenomic or metatranscriptomic sequence data.\nIt accepts various types of input files, including .fastq files from metagenomes or metatranscriptomes after host data removal and quality trimming, alignment result files (.sam or .bam), and gene information with count data in .tsv and .biom formats.\nYou can perform microbial community analysis and functional analysis within the community using pangenome databases such as MetaPhlAn and ChocoPhlAn. Additionally, you can acquire genome information and pathway details using UniRef, MetaCyc, and MinPath.# download humann\n$ conda create --name biobakery3 python=3.7\n$ conda activate biobakery3\n$ conda install humann –c biobakery3\n# download database\n$ humann_databases --download chocophlan full $INSTALL_LOCATION --update-config yes\n$ humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION --update-config yes\n$ humann_databases --download utility_mapping full $INSTALL_LOCATION --update-config yes\n# paired read concatenation\n$ cat kneaddata.trimmed_paired_1.fastq kneaddata.trimmed_paired_2.fastq > kneaddata.trimmed.fastq\n# running humann\n$ humann --input sample_kneaddata_paired_1.fastq --output $OUTPUT_DIR\n# humann result’s features\n$ humann_join_tables -i $OUTPUT_DIR -o sample_pathcoverage.tsv –-file_name pathcoverage \n$ humann_barplot –-input sample_pathcoverage.tsv –-focal-feature $PATHWAY_NAME –-outfile sample_path\n\nThe explanation related to HUMAnN installation and DB download is described once more.\n\nWhen conducting HUMAnN analysis, you can obtain information about gene families and pathways.\nAmong them, you can use pathway information stored in the sample_pathabundance.tsv and sample_pathcoverage.tsv files to create bar plots, allowing you to visualize the proportion of microorganisms involved in specific pathways.\nHUMAnN generates several files (e.g., bowtie results, diamond results), and you can use these for additional analyses.\n\n\n\nExample of a barplot visualization result of path information derived from HUMAnN results","type":"content","url":"/read-based-1","position":1},{"hierarchy":{"lvl1":"Sequencing"},"type":"lvl1","url":"/sequencing-1","position":0},{"hierarchy":{"lvl1":"Sequencing"},"content":"Metatranscriptomic sequencing captures the actively expressed genes within a microbial community at a given point in time, providing a snapshot of community-level gene expression. Unlike DNA-based metagenomics, RNA is inherently unstable and degrades rapidly, making proper sample preservation, RNA extraction, and library preparation critically important. This chapter details the complete wet-lab protocol for metatranscriptomic sequencing, from fecal sample collection and RNA extraction through rRNA depletion and Illumina library preparation. Special attention is given to maintaining RNA integrity throughout the workflow, as the quality of the extracted RNA directly determines the reliability of downstream expression analyses.","type":"content","url":"/sequencing-1","position":1},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Biological samples"},"type":"lvl2","url":"/sequencing-1#biological-samples","position":2},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Biological samples"},"content":"RNA is highly susceptible to degradation by ubiquitous RNases, making rapid and effective preservation essential for metatranscriptomic studies. RNAlater is a non-toxic aqueous reagent that permeates tissues and stabilizes RNA by inactivating RNases, allowing sample storage at -80°C without significant transcript degradation. Proper sample-to-reagent ratios and immediate processing are critical to ensuring that the captured transcriptional profile accurately reflects the in vivo state of the microbial community.\n\nProcess 500 µL of RNAlater (Ambion) for every 1 g of fecal sample and store it at -80°C","type":"content","url":"/sequencing-1#biological-samples","position":3},{"hierarchy":{"lvl1":"Sequencing","lvl2":"RNA preparation"},"type":"lvl2","url":"/sequencing-1#rna-preparation","position":4},{"hierarchy":{"lvl1":"Sequencing","lvl2":"RNA preparation"},"content":"Total RNA extraction from fecal samples requires a combination of mechanical lysis (bead-beating) and chemical purification to efficiently lyse diverse microbial cell types while preserving RNA integrity. The protocol below uses a phenol-chloroform extraction followed by silica column purification (RNeasy mini plus kit) to obtain high-quality total RNA. A critical downstream step is DNase treatment (TURBO DNase) to remove co-extracted genomic DNA, which would otherwise introduce false signals in expression analyses.","type":"content","url":"/sequencing-1#rna-preparation","position":5},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Reagents","lvl2":"RNA preparation"},"type":"lvl3","url":"/sequencing-1#reagents","position":6},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Reagents","lvl2":"RNA preparation"},"content":"-RLT buffer (Qiagen), β-mercaptoethanol, Superase-In 20U/μL (Thermo Fisher Scientific), proteinase K (20mg/mL), 100% ethanol, 70% ethanol, 3M sodium acetate, phenol/chloroform/isoamyl alcohol 25:24:1 (pH5.2), RNase-free water\n-kit RNeasy mini plus kit (Qiagen), TURBO DNA-free™ (Ambion)","type":"content","url":"/sequencing-1#reagents","position":7},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Equipment","lvl2":"RNA preparation"},"type":"lvl3","url":"/sequencing-1#equipment","position":8},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Equipment","lvl2":"RNA preparation"},"content":"FastPrep-24™ 5G(MP), pipette, aerosol barrier pipette tips, microcetrifuge, 1mm zirconia/silica beadsOptional; Qubit fluorometer (Thermo Fisher Scientific), Fragment analyzer","type":"content","url":"/sequencing-1#equipment","position":9},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Stock solutions","lvl2":"RNA preparation"},"type":"lvl3","url":"/sequencing-1#stock-solutions","position":10},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Stock solutions","lvl2":"RNA preparation"},"content":"Stock solution A\n\nvolume\n\nRLT buffer(Qiagen)\n\n975 μL\n\nβ-mercaptoethanol\n\n10 μL\n\nSuperase-In, 20U/μL\n\n15 μL\n\nTotal\n\n1 ml","type":"content","url":"/sequencing-1#stock-solutions","position":11},{"hierarchy":{"lvl1":"Sequencing","lvl3":"RNA preparation","lvl2":"RNA preparation"},"type":"lvl3","url":"/sequencing-1#rna-preparation-1","position":12},{"hierarchy":{"lvl1":"Sequencing","lvl3":"RNA preparation","lvl2":"RNA preparation"},"content":"Place fecal sample and beads in each screw-top tube and process the reaction mixture.| Each tube |  |\n| --- | --- |\n| Fecal sample | 150mg |\n| 1.0mm zirconia/silica beads | ~20 |\n| Stock solution A | 600 μL |\n\nPerform two cycles of FastPrep-24™ at 6.0 m/s for 40 seconds each.\n\nCentrifuge at 12,000 rpm for 3 minutes, transfer 600 μL of the supernatant to an e-tube.\n\nAdd 15 μL of Proteinase K and incubate at room temperature for 10 minutes.\n\nCentrifuge at 12,000 rpm for 3 minutes, and transfer the supernatant to a new e-tube.\n\nTreat with an equal volume of phenol/chloroform/isoamyl alcohol 25:24:1 and vortex for 3 minutes.\n\nCentrifuge at 12,000 rpm for 3 minutes, and repeat the process of transferring the supernatant to a new e-tube twice.\n\nAdd 0.1 times the volume of 3M sodium acetate and 2.5 times the volume of ethanol to the supernatant and incubate on ice for 30 minutes.\n\nCentrifuge at 12,000 rpm at 4°C for 30 minutes and remove the supernatant.\n\nResuspend the pellet in 100 μL of distilled water and add 600 μL of RLT plus buffer from the RNeasy plus mini kit.\n\nApply the solution from step 10 to the gDNA eliminator spin column of the RNeasy plus mini kit.\n\nCentrifuge at 12,000 rpm for 30 seconds, discard the column, and treat the flow-through with 70% ethanol at a 1:1 ratio.\n\nTransfer the solution from step 12 to the RNeasy spin column, centrifuge at 12,000 rpm for 15 seconds, and discard the flow-through.\n\nAdd 700 μL of RW1 buffer to the column, centrifuge at 12,000 rpm for 15 seconds, and discard the flow-through.\n\nAdd 500 μL of RPE buffer to the column, centrifuge at 12,000 rpm for 15 seconds, and discard the flow-through.\n\nAdd another 500 μL of RPE buffer to the column, centrifuge at 12,000 rpm for 2 minutes, and transfer the column to a new e-tube.\n\nTreat the column’s membrane with 30-50 μL of RNase-free water and centrifuge at 12,000 rpm for 1 minute to obtain RNA.\n\n[Optional: RNA QC]\n\nMeasure the RNA concentration using a Qubit fluorometer*.*A NanoDrop spectrophotometer can also be used, but for accurate concentration measurement, it is recommended to use a Qubit fluorometer.\n\nPerform QC of the obtained RNA using a Fragment analyzer.\n\n\n\nExample of RNA sample analysis results using a Fragment analyzer\n\nPrepare the 10X TURBO DNase buffer to a 1X concentration and add 1 μL of TURBO DNase to the RNA.\n\nIncubate at 37°C for 20-30 minutes.\n\nAdd 0.1 times the volume of DNase inactivation reagent.\n\nIncubate at room temperature for 5 minutes.\n\nCentrifuge at 10,000 rpm for 1 minute and 30 seconds, and transfer the supernatant to a new e-tube.","type":"content","url":"/sequencing-1#rna-preparation-1","position":13},{"hierarchy":{"lvl1":"Sequencing","lvl3":"rRNA depletion","lvl2":"RNA preparation"},"type":"lvl3","url":"/sequencing-1#rrna-depletion","position":14},{"hierarchy":{"lvl1":"Sequencing","lvl3":"rRNA depletion","lvl2":"RNA preparation"},"content":"Ribosomal RNA (rRNA) typically constitutes 80–90% of total RNA in microbial samples, vastly outnumbering messenger RNA (mRNA). Without rRNA depletion, the majority of sequencing reads would be uninformative for gene expression analysis. Because metatranscriptomic samples contain RNA from both the host and diverse bacterial species, two separate depletion kits are applied sequentially: one targeting host (plant/mammalian) rRNA and another targeting bacterial rRNA using probe-based enzymatic degradation (Ribo-Zero Plus).\n\nHost rRNA remove Illumina TruSeq Stranded Total RNA Library Prep Plant Kit (Illumina, # 20020611)\n\nBacterial rRNA remove Illumina Stranded Total RNA Library Prep with Ribo-Zero Plus kit (Illumina, #20040529)","type":"content","url":"/sequencing-1#rrna-depletion","position":15},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Sequencing"},"type":"lvl2","url":"/sequencing-1#sequencing","position":16},{"hierarchy":{"lvl1":"Sequencing","lvl2":"Sequencing"},"content":"Once rRNA-depleted RNA is obtained, it is converted into a strand-specific cDNA library suitable for Illumina sequencing. Strand-specific (stranded) library preparation preserves the information about which DNA strand was originally transcribed, enabling accurate determination of sense versus antisense transcription — a distinction that is particularly important in prokaryotic genomes where overlapping genes on opposite strands are common.","type":"content","url":"/sequencing-1#sequencing","position":17},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing library preparation","lvl2":"Sequencing"},"type":"lvl3","url":"/sequencing-1#sequencing-library-preparation","position":18},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing library preparation","lvl2":"Sequencing"},"content":"Perform mRNA fragmentation using divalent cations.\n\nFirst strand cDNA synthesis using SuperScript II reverse transcriptase (Invitrogen, #18064014) with random primers.\n\nSecond strand cDNA synthesis using DNA Polymerase I, RNase H, and dUTP.\n\nPerform end repair on synthesized cDNA fragments, followed by the attachment of a single ‘A’ base and adaptor ligation.\n\nPerform PCR to create the cDNA library for sequencing.*Progress Sequencing library quantificationKAPA Library Quantificatoin kits for Illumina Sequecing platforms according to the qPCR Quantification Protocol Guide (KAPA BIOSYSTEMS, #KK4854)*Conduct quality control (QC) for the sequencing library.TapeStation D1000 ScreenTape (Agilent Technologies, # 5067-5582)","type":"content","url":"/sequencing-1#sequencing-library-preparation","position":19},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing","lvl2":"Sequencing"},"type":"lvl3","url":"/sequencing-1#sequencing-1","position":20},{"hierarchy":{"lvl1":"Sequencing","lvl3":"Sequencing","lvl2":"Sequencing"},"content":"Perform paired-end (2×150 bp) sequencing on an Illumina NovaSeq (Illumina) instrument using the final indexed sequencing library.","type":"content","url":"/sequencing-1#sequencing-1","position":21},{"hierarchy":{"lvl1":"Transcript taxonomy classification"},"type":"lvl1","url":"/taxonomy","position":0},{"hierarchy":{"lvl1":"Transcript taxonomy classification"},"content":"In metatranscriptome analysis, just as taxonomy profiling is conducted in metagenome analysis, performing taxonomy assignment based on reads or contigs allows us to obtain information about microorganisms actively expressing themselves in the environment.In addition to the approach using the Kaiju tool, which is introduced in the metagenome SOP, there’s a simple method for taxonomy analysis available through the \n\nOne Codex web server.\nThe One Codex website accepts fasta or fastq files as input data and provides results accordingly.\nFor taxonomy analysis, One Codex employs its own database containing over 110,000 genomes and targeted loci databases such as 16S, 5S, 23S, gyrB, ITS, and more.\n\n\n\nOne codex reference database\n\n\n\nexample of taxonomy assignment results using the One Codex web server\n\nYou can compare taxonomy information not only at the DNA level but also from RNA data.\nIf you have metagenomic information, it can be used for reference. In cases where metagenomic information is unavailable, you can verify taxonomy at the RNA level.\nThe analysis results allow for visualization of cluster composition and read count ratios at each taxonomy level, from phylum to species. Additionally, a taxonomy chart reflecting hierarchical taxonomy levels is available for examination.","type":"content","url":"/taxonomy","position":1}]}